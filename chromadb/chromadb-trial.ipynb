{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f299bc8-96ad-4382-ab04-6930e9ea352a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/apps/mamba/1.5.1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import replicate\n",
    "import chromadb\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5768577-6ba9-4b9b-8c80-134a055b6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from replicate.client import Client\n",
    "\n",
    "replicate = Client(api_token=\"r8_IbZu0U3qUJ5ZC0TzzMm6xCJ6yU5UxVi16Ejo4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25ee767-13ef-4e1b-b66a-3f5d10c215ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./persistent-client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4554cb53-6e16-46c1-8778-5622932a78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_files_to_collection(collection, datasets_dir):\n",
    "  \"\"\"\n",
    "  Adds text files from a directory to a collection with generated IDs.\n",
    "\n",
    "  Args:\n",
    "      collection: The collection object to add documents and IDs to.\n",
    "      datasets_dir: The directory containing the text files.\n",
    "  \"\"\"\n",
    "  text_files = [os.path.join(datasets_dir, filename) for filename in os.listdir(datasets_dir)\n",
    "                if filename.endswith(\".txt\")]\n",
    "\n",
    "  if not text_files:\n",
    "    print(f\"No text files found in directory: {datasets_dir}\")\n",
    "    return\n",
    "\n",
    "  start_id = 1 \n",
    "  for i, filename in enumerate(text_files):\n",
    "    document_id = f\"doc_{start_id + i}\"\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "      document_content = f.read()\n",
    "        \n",
    "    collection.add(documents=[document_content], ids=[document_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad32215-d2b6-4019-8a4a-a43fe84a4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-03-31 13:54:37.488415229 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779348, index: 0, mask: {1, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.533519433 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779349, index: 1, mask: {2, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.553714044 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779350, index: 2, mask: {3, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.560185717 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779351, index: 3, mask: {4, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.578953501 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779352, index: 4, mask: {5, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.594112403 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779353, index: 5, mask: {6, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.609232953 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779354, index: 6, mask: {7, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.624388159 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779355, index: 7, mask: {8, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.639551049 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779356, index: 8, mask: {9, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.654712827 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779357, index: 9, mask: {10, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.669873173 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779358, index: 10, mask: {11, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.679192828 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779359, index: 11, mask: {12, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.690179525 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779360, index: 12, mask: {13, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.705336213 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779361, index: 13, mask: {14, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.720497270 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779362, index: 14, mask: {15, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.735662174 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779363, index: 15, mask: {16, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.750826697 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779364, index: 16, mask: {17, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.765985991 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779365, index: 17, mask: {18, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.781144122 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779366, index: 18, mask: {19, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.795195581 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779367, index: 19, mask: {20, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.806179402 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779368, index: 20, mask: {21, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.821339978 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779369, index: 21, mask: {22, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.836498360 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779370, index: 22, mask: {23, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.851656050 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779371, index: 23, mask: {24, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.866822187 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779372, index: 24, mask: {25, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.881983303 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779373, index: 25, mask: {26, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.897139130 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779374, index: 26, mask: {27, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.912284297 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779375, index: 27, mask: {28, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.927440695 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779376, index: 28, mask: {29, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.942599307 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779377, index: 29, mask: {30, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.957754362 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779378, index: 30, mask: {31, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.972911512 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779379, index: 31, mask: {32, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:37.988072358 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779380, index: 32, mask: {33, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.003179062 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779381, index: 33, mask: {34, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.018338746 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779382, index: 34, mask: {35, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.033493732 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779383, index: 35, mask: {36, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.037195809 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779384, index: 36, mask: {37, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.048179820 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779385, index: 37, mask: {38, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.063340516 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779386, index: 38, mask: {39, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.078498778 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779387, index: 39, mask: {40, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.093655907 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779388, index: 40, mask: {41, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.108812015 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779389, index: 41, mask: {42, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.123971007 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779390, index: 42, mask: {43, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.139128858 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779391, index: 43, mask: {44, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.169441935 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779393, index: 45, mask: {46, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-03-31 13:54:38.184603903 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3779394, index: 46, mask: {47, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "Add of existing embedding ID: doc_1\n",
      "Add of existing embedding ID: doc_2\n",
      "Add of existing embedding ID: doc_3\n",
      "Add of existing embedding ID: doc_4\n",
      "Add of existing embedding ID: doc_5\n",
      "Add of existing embedding ID: doc_6\n",
      "Add of existing embedding ID: doc_7\n",
      "Add of existing embedding ID: doc_8\n",
      "Add of existing embedding ID: doc_9\n",
      "Add of existing embedding ID: doc_10\n",
      "Add of existing embedding ID: doc_11\n",
      "Add of existing embedding ID: doc_12\n",
      "Add of existing embedding ID: doc_13\n",
      "Add of existing embedding ID: doc_14\n",
      "Add of existing embedding ID: doc_15\n",
      "Add of existing embedding ID: doc_16\n",
      "Add of existing embedding ID: doc_17\n",
      "Add of existing embedding ID: doc_18\n",
      "Add of existing embedding ID: doc_19\n",
      "Add of existing embedding ID: doc_20\n",
      "Add of existing embedding ID: doc_21\n",
      "Add of existing embedding ID: doc_22\n",
      "Add of existing embedding ID: doc_23\n",
      "Add of existing embedding ID: doc_24\n",
      "Add of existing embedding ID: doc_25\n",
      "Add of existing embedding ID: doc_26\n",
      "Add of existing embedding ID: doc_27\n",
      "Add of existing embedding ID: doc_28\n",
      "Add of existing embedding ID: doc_29\n",
      "Add of existing embedding ID: doc_30\n",
      "Add of existing embedding ID: doc_31\n",
      "Add of existing embedding ID: doc_32\n",
      "Add of existing embedding ID: doc_33\n",
      "Add of existing embedding ID: doc_34\n",
      "Add of existing embedding ID: doc_35\n",
      "Add of existing embedding ID: doc_36\n",
      "Add of existing embedding ID: doc_37\n",
      "Add of existing embedding ID: doc_38\n",
      "Add of existing embedding ID: doc_39\n",
      "Add of existing embedding ID: doc_40\n",
      "Add of existing embedding ID: doc_41\n",
      "Add of existing embedding ID: doc_42\n",
      "Add of existing embedding ID: doc_43\n",
      "Add of existing embedding ID: doc_44\n",
      "Add of existing embedding ID: doc_45\n",
      "Add of existing embedding ID: doc_46\n",
      "Add of existing embedding ID: doc_47\n",
      "Add of existing embedding ID: doc_48\n",
      "Add of existing embedding ID: doc_49\n",
      "Add of existing embedding ID: doc_50\n",
      "Add of existing embedding ID: doc_51\n",
      "Add of existing embedding ID: doc_52\n",
      "Add of existing embedding ID: doc_53\n",
      "Add of existing embedding ID: doc_54\n",
      "Add of existing embedding ID: doc_55\n",
      "Add of existing embedding ID: doc_56\n",
      "Add of existing embedding ID: doc_57\n",
      "Add of existing embedding ID: doc_58\n",
      "Add of existing embedding ID: doc_59\n",
      "Add of existing embedding ID: doc_60\n",
      "Add of existing embedding ID: doc_61\n",
      "Add of existing embedding ID: doc_62\n",
      "Add of existing embedding ID: doc_63\n",
      "Add of existing embedding ID: doc_64\n",
      "Add of existing embedding ID: doc_65\n",
      "Add of existing embedding ID: doc_66\n",
      "Add of existing embedding ID: doc_67\n",
      "Add of existing embedding ID: doc_68\n",
      "Add of existing embedding ID: doc_69\n",
      "Add of existing embedding ID: doc_70\n",
      "Add of existing embedding ID: doc_71\n",
      "Add of existing embedding ID: doc_72\n",
      "Add of existing embedding ID: doc_73\n",
      "Add of existing embedding ID: doc_74\n",
      "Add of existing embedding ID: doc_75\n",
      "Add of existing embedding ID: doc_76\n",
      "Add of existing embedding ID: doc_77\n",
      "Add of existing embedding ID: doc_78\n",
      "Add of existing embedding ID: doc_79\n",
      "Add of existing embedding ID: doc_80\n",
      "Add of existing embedding ID: doc_81\n",
      "Add of existing embedding ID: doc_82\n",
      "Add of existing embedding ID: doc_83\n",
      "Add of existing embedding ID: doc_84\n",
      "Add of existing embedding ID: doc_85\n",
      "Add of existing embedding ID: doc_86\n",
      "Add of existing embedding ID: doc_87\n",
      "Add of existing embedding ID: doc_88\n",
      "Add of existing embedding ID: doc_89\n",
      "Add of existing embedding ID: doc_90\n",
      "Add of existing embedding ID: doc_91\n",
      "Add of existing embedding ID: doc_92\n",
      "Add of existing embedding ID: doc_93\n",
      "Add of existing embedding ID: doc_94\n",
      "Add of existing embedding ID: doc_95\n",
      "Add of existing embedding ID: doc_96\n",
      "Add of existing embedding ID: doc_97\n",
      "Add of existing embedding ID: doc_98\n",
      "Add of existing embedding ID: doc_99\n",
      "Add of existing embedding ID: doc_100\n",
      "Add of existing embedding ID: doc_101\n",
      "Add of existing embedding ID: doc_102\n",
      "Add of existing embedding ID: doc_103\n",
      "Add of existing embedding ID: doc_104\n",
      "Add of existing embedding ID: doc_105\n",
      "Add of existing embedding ID: doc_106\n",
      "Add of existing embedding ID: doc_107\n",
      "Add of existing embedding ID: doc_108\n",
      "Add of existing embedding ID: doc_109\n",
      "Add of existing embedding ID: doc_110\n",
      "Add of existing embedding ID: doc_111\n",
      "Add of existing embedding ID: doc_112\n",
      "Add of existing embedding ID: doc_113\n",
      "Add of existing embedding ID: doc_114\n",
      "Add of existing embedding ID: doc_115\n",
      "Add of existing embedding ID: doc_116\n",
      "Add of existing embedding ID: doc_117\n",
      "Add of existing embedding ID: doc_118\n",
      "Add of existing embedding ID: doc_119\n",
      "Add of existing embedding ID: doc_120\n",
      "Add of existing embedding ID: doc_121\n",
      "Add of existing embedding ID: doc_122\n",
      "Add of existing embedding ID: doc_123\n",
      "Add of existing embedding ID: doc_124\n",
      "Add of existing embedding ID: doc_125\n",
      "Add of existing embedding ID: doc_126\n",
      "Add of existing embedding ID: doc_127\n",
      "Add of existing embedding ID: doc_128\n",
      "Add of existing embedding ID: doc_129\n",
      "Add of existing embedding ID: doc_130\n",
      "Add of existing embedding ID: doc_131\n",
      "Add of existing embedding ID: doc_132\n",
      "Add of existing embedding ID: doc_133\n",
      "Add of existing embedding ID: doc_134\n",
      "Add of existing embedding ID: doc_135\n",
      "Insert of existing embedding ID: doc_1\n",
      "Add of existing embedding ID: doc_1\n",
      "Insert of existing embedding ID: doc_2\n",
      "Add of existing embedding ID: doc_2\n",
      "Insert of existing embedding ID: doc_3\n",
      "Add of existing embedding ID: doc_3\n",
      "Insert of existing embedding ID: doc_4\n",
      "Add of existing embedding ID: doc_4\n",
      "Insert of existing embedding ID: doc_5\n",
      "Add of existing embedding ID: doc_5\n",
      "Insert of existing embedding ID: doc_6\n",
      "Add of existing embedding ID: doc_6\n",
      "Insert of existing embedding ID: doc_7\n",
      "Add of existing embedding ID: doc_7\n",
      "Insert of existing embedding ID: doc_8\n",
      "Add of existing embedding ID: doc_8\n",
      "Insert of existing embedding ID: doc_9\n",
      "Add of existing embedding ID: doc_9\n",
      "Insert of existing embedding ID: doc_10\n",
      "Add of existing embedding ID: doc_10\n",
      "Insert of existing embedding ID: doc_11\n",
      "Add of existing embedding ID: doc_11\n",
      "Insert of existing embedding ID: doc_12\n",
      "Add of existing embedding ID: doc_12\n",
      "Insert of existing embedding ID: doc_13\n",
      "Add of existing embedding ID: doc_13\n",
      "Insert of existing embedding ID: doc_14\n",
      "Add of existing embedding ID: doc_14\n",
      "Insert of existing embedding ID: doc_15\n",
      "Add of existing embedding ID: doc_15\n",
      "Insert of existing embedding ID: doc_16\n",
      "Add of existing embedding ID: doc_16\n",
      "Insert of existing embedding ID: doc_17\n",
      "Add of existing embedding ID: doc_17\n",
      "Insert of existing embedding ID: doc_18\n",
      "Add of existing embedding ID: doc_18\n",
      "Insert of existing embedding ID: doc_19\n",
      "Add of existing embedding ID: doc_19\n",
      "Insert of existing embedding ID: doc_20\n",
      "Add of existing embedding ID: doc_20\n",
      "Insert of existing embedding ID: doc_21\n",
      "Add of existing embedding ID: doc_21\n",
      "Insert of existing embedding ID: doc_22\n",
      "Add of existing embedding ID: doc_22\n",
      "Insert of existing embedding ID: doc_23\n",
      "Add of existing embedding ID: doc_23\n",
      "Insert of existing embedding ID: doc_24\n",
      "Add of existing embedding ID: doc_24\n",
      "Insert of existing embedding ID: doc_25\n",
      "Add of existing embedding ID: doc_25\n",
      "Insert of existing embedding ID: doc_26\n",
      "Add of existing embedding ID: doc_26\n",
      "Insert of existing embedding ID: doc_27\n",
      "Add of existing embedding ID: doc_27\n",
      "Insert of existing embedding ID: doc_28\n",
      "Add of existing embedding ID: doc_28\n",
      "Insert of existing embedding ID: doc_29\n",
      "Add of existing embedding ID: doc_29\n",
      "Insert of existing embedding ID: doc_30\n",
      "Add of existing embedding ID: doc_30\n",
      "Insert of existing embedding ID: doc_31\n",
      "Add of existing embedding ID: doc_31\n",
      "Insert of existing embedding ID: doc_32\n",
      "Add of existing embedding ID: doc_32\n",
      "Insert of existing embedding ID: doc_33\n",
      "Add of existing embedding ID: doc_33\n",
      "Insert of existing embedding ID: doc_34\n",
      "Add of existing embedding ID: doc_34\n",
      "Insert of existing embedding ID: doc_35\n",
      "Add of existing embedding ID: doc_35\n",
      "Insert of existing embedding ID: doc_36\n",
      "Add of existing embedding ID: doc_36\n",
      "Insert of existing embedding ID: doc_37\n",
      "Add of existing embedding ID: doc_37\n",
      "Insert of existing embedding ID: doc_38\n",
      "Add of existing embedding ID: doc_38\n",
      "Insert of existing embedding ID: doc_39\n",
      "Add of existing embedding ID: doc_39\n",
      "Insert of existing embedding ID: doc_40\n",
      "Add of existing embedding ID: doc_40\n",
      "Insert of existing embedding ID: doc_41\n",
      "Add of existing embedding ID: doc_41\n",
      "Insert of existing embedding ID: doc_42\n",
      "Add of existing embedding ID: doc_42\n",
      "Insert of existing embedding ID: doc_43\n",
      "Add of existing embedding ID: doc_43\n",
      "Insert of existing embedding ID: doc_44\n",
      "Add of existing embedding ID: doc_44\n",
      "Insert of existing embedding ID: doc_45\n",
      "Add of existing embedding ID: doc_45\n",
      "Insert of existing embedding ID: doc_46\n",
      "Add of existing embedding ID: doc_46\n",
      "Insert of existing embedding ID: doc_47\n",
      "Add of existing embedding ID: doc_47\n",
      "Insert of existing embedding ID: doc_48\n",
      "Add of existing embedding ID: doc_48\n",
      "Insert of existing embedding ID: doc_49\n",
      "Add of existing embedding ID: doc_49\n",
      "Insert of existing embedding ID: doc_50\n",
      "Add of existing embedding ID: doc_50\n",
      "Insert of existing embedding ID: doc_51\n",
      "Add of existing embedding ID: doc_51\n",
      "Insert of existing embedding ID: doc_52\n",
      "Add of existing embedding ID: doc_52\n",
      "Insert of existing embedding ID: doc_53\n",
      "Add of existing embedding ID: doc_53\n",
      "Insert of existing embedding ID: doc_54\n",
      "Add of existing embedding ID: doc_54\n",
      "Insert of existing embedding ID: doc_55\n",
      "Add of existing embedding ID: doc_55\n",
      "Insert of existing embedding ID: doc_56\n",
      "Add of existing embedding ID: doc_56\n",
      "Insert of existing embedding ID: doc_57\n",
      "Add of existing embedding ID: doc_57\n",
      "Insert of existing embedding ID: doc_58\n",
      "Add of existing embedding ID: doc_58\n",
      "Insert of existing embedding ID: doc_59\n",
      "Add of existing embedding ID: doc_59\n",
      "Insert of existing embedding ID: doc_60\n",
      "Add of existing embedding ID: doc_60\n",
      "Insert of existing embedding ID: doc_61\n",
      "Add of existing embedding ID: doc_61\n",
      "Insert of existing embedding ID: doc_62\n",
      "Add of existing embedding ID: doc_62\n",
      "Insert of existing embedding ID: doc_63\n",
      "Add of existing embedding ID: doc_63\n",
      "Insert of existing embedding ID: doc_64\n",
      "Add of existing embedding ID: doc_64\n",
      "Insert of existing embedding ID: doc_65\n",
      "Add of existing embedding ID: doc_65\n",
      "Insert of existing embedding ID: doc_66\n",
      "Add of existing embedding ID: doc_66\n",
      "Insert of existing embedding ID: doc_67\n",
      "Add of existing embedding ID: doc_67\n",
      "Insert of existing embedding ID: doc_68\n",
      "Add of existing embedding ID: doc_68\n",
      "Insert of existing embedding ID: doc_69\n",
      "Add of existing embedding ID: doc_69\n",
      "Insert of existing embedding ID: doc_70\n",
      "Add of existing embedding ID: doc_70\n",
      "Insert of existing embedding ID: doc_71\n",
      "Add of existing embedding ID: doc_71\n",
      "Insert of existing embedding ID: doc_72\n",
      "Add of existing embedding ID: doc_72\n",
      "Insert of existing embedding ID: doc_73\n",
      "Add of existing embedding ID: doc_73\n",
      "Insert of existing embedding ID: doc_74\n",
      "Add of existing embedding ID: doc_74\n",
      "Insert of existing embedding ID: doc_75\n",
      "Add of existing embedding ID: doc_75\n",
      "Insert of existing embedding ID: doc_76\n",
      "Add of existing embedding ID: doc_76\n",
      "Insert of existing embedding ID: doc_77\n",
      "Add of existing embedding ID: doc_77\n",
      "Insert of existing embedding ID: doc_78\n",
      "Add of existing embedding ID: doc_78\n",
      "Insert of existing embedding ID: doc_79\n",
      "Add of existing embedding ID: doc_79\n",
      "Insert of existing embedding ID: doc_80\n",
      "Add of existing embedding ID: doc_80\n",
      "Insert of existing embedding ID: doc_81\n",
      "Add of existing embedding ID: doc_81\n",
      "Insert of existing embedding ID: doc_82\n",
      "Add of existing embedding ID: doc_82\n",
      "Insert of existing embedding ID: doc_83\n",
      "Add of existing embedding ID: doc_83\n",
      "Insert of existing embedding ID: doc_84\n",
      "Add of existing embedding ID: doc_84\n",
      "Insert of existing embedding ID: doc_85\n",
      "Add of existing embedding ID: doc_85\n",
      "Insert of existing embedding ID: doc_86\n",
      "Add of existing embedding ID: doc_86\n",
      "Insert of existing embedding ID: doc_87\n",
      "Add of existing embedding ID: doc_87\n",
      "Insert of existing embedding ID: doc_88\n",
      "Add of existing embedding ID: doc_88\n",
      "Insert of existing embedding ID: doc_89\n",
      "Add of existing embedding ID: doc_89\n",
      "Insert of existing embedding ID: doc_90\n",
      "Add of existing embedding ID: doc_90\n",
      "Insert of existing embedding ID: doc_91\n",
      "Add of existing embedding ID: doc_91\n",
      "Insert of existing embedding ID: doc_92\n",
      "Add of existing embedding ID: doc_92\n",
      "Insert of existing embedding ID: doc_93\n",
      "Add of existing embedding ID: doc_93\n",
      "Insert of existing embedding ID: doc_94\n",
      "Add of existing embedding ID: doc_94\n",
      "Insert of existing embedding ID: doc_95\n",
      "Add of existing embedding ID: doc_95\n",
      "Insert of existing embedding ID: doc_96\n",
      "Add of existing embedding ID: doc_96\n",
      "Insert of existing embedding ID: doc_97\n",
      "Add of existing embedding ID: doc_97\n",
      "Insert of existing embedding ID: doc_98\n",
      "Add of existing embedding ID: doc_98\n",
      "Insert of existing embedding ID: doc_99\n",
      "Add of existing embedding ID: doc_99\n",
      "Insert of existing embedding ID: doc_100\n",
      "Add of existing embedding ID: doc_100\n",
      "Insert of existing embedding ID: doc_101\n",
      "Add of existing embedding ID: doc_101\n",
      "Insert of existing embedding ID: doc_102\n",
      "Add of existing embedding ID: doc_102\n",
      "Insert of existing embedding ID: doc_103\n",
      "Add of existing embedding ID: doc_103\n",
      "Insert of existing embedding ID: doc_104\n",
      "Add of existing embedding ID: doc_104\n",
      "Insert of existing embedding ID: doc_105\n",
      "Add of existing embedding ID: doc_105\n",
      "Insert of existing embedding ID: doc_106\n",
      "Add of existing embedding ID: doc_106\n",
      "Insert of existing embedding ID: doc_107\n",
      "Add of existing embedding ID: doc_107\n",
      "Insert of existing embedding ID: doc_108\n",
      "Add of existing embedding ID: doc_108\n",
      "Insert of existing embedding ID: doc_109\n",
      "Add of existing embedding ID: doc_109\n",
      "Insert of existing embedding ID: doc_110\n",
      "Add of existing embedding ID: doc_110\n",
      "Insert of existing embedding ID: doc_111\n",
      "Add of existing embedding ID: doc_111\n",
      "Insert of existing embedding ID: doc_112\n",
      "Add of existing embedding ID: doc_112\n",
      "Insert of existing embedding ID: doc_113\n",
      "Add of existing embedding ID: doc_113\n",
      "Insert of existing embedding ID: doc_114\n",
      "Add of existing embedding ID: doc_114\n",
      "Insert of existing embedding ID: doc_115\n",
      "Add of existing embedding ID: doc_115\n",
      "Insert of existing embedding ID: doc_116\n",
      "Add of existing embedding ID: doc_116\n",
      "Insert of existing embedding ID: doc_117\n",
      "Add of existing embedding ID: doc_117\n",
      "Insert of existing embedding ID: doc_118\n",
      "Add of existing embedding ID: doc_118\n",
      "Insert of existing embedding ID: doc_119\n",
      "Add of existing embedding ID: doc_119\n",
      "Insert of existing embedding ID: doc_120\n",
      "Add of existing embedding ID: doc_120\n",
      "Insert of existing embedding ID: doc_121\n",
      "Add of existing embedding ID: doc_121\n",
      "Insert of existing embedding ID: doc_122\n",
      "Add of existing embedding ID: doc_122\n",
      "Insert of existing embedding ID: doc_123\n",
      "Add of existing embedding ID: doc_123\n",
      "Insert of existing embedding ID: doc_124\n",
      "Add of existing embedding ID: doc_124\n",
      "Insert of existing embedding ID: doc_125\n",
      "Add of existing embedding ID: doc_125\n",
      "Insert of existing embedding ID: doc_126\n",
      "Add of existing embedding ID: doc_126\n",
      "Insert of existing embedding ID: doc_127\n",
      "Add of existing embedding ID: doc_127\n",
      "Insert of existing embedding ID: doc_128\n",
      "Add of existing embedding ID: doc_128\n",
      "Insert of existing embedding ID: doc_129\n",
      "Add of existing embedding ID: doc_129\n",
      "Insert of existing embedding ID: doc_130\n",
      "Add of existing embedding ID: doc_130\n",
      "Insert of existing embedding ID: doc_131\n",
      "Add of existing embedding ID: doc_131\n",
      "Insert of existing embedding ID: doc_132\n",
      "Add of existing embedding ID: doc_132\n",
      "Insert of existing embedding ID: doc_133\n",
      "Add of existing embedding ID: doc_133\n",
      "Insert of existing embedding ID: doc_134\n",
      "Add of existing embedding ID: doc_134\n",
      "Insert of existing embedding ID: doc_135\n",
      "Add of existing embedding ID: doc_135\n",
      "Insert of existing embedding ID: doc_136\n",
      "Add of existing embedding ID: doc_136\n",
      "Insert of existing embedding ID: doc_137\n",
      "Add of existing embedding ID: doc_137\n",
      "Insert of existing embedding ID: doc_138\n",
      "Add of existing embedding ID: doc_138\n",
      "Insert of existing embedding ID: doc_139\n",
      "Add of existing embedding ID: doc_139\n",
      "Insert of existing embedding ID: doc_140\n",
      "Add of existing embedding ID: doc_140\n",
      "Insert of existing embedding ID: doc_141\n",
      "Add of existing embedding ID: doc_141\n",
      "Insert of existing embedding ID: doc_142\n",
      "Add of existing embedding ID: doc_142\n",
      "Insert of existing embedding ID: doc_143\n",
      "Add of existing embedding ID: doc_143\n",
      "Insert of existing embedding ID: doc_144\n",
      "Add of existing embedding ID: doc_144\n",
      "Insert of existing embedding ID: doc_145\n",
      "Add of existing embedding ID: doc_145\n",
      "Insert of existing embedding ID: doc_146\n",
      "Add of existing embedding ID: doc_146\n",
      "Insert of existing embedding ID: doc_147\n",
      "Add of existing embedding ID: doc_147\n",
      "Insert of existing embedding ID: doc_148\n",
      "Add of existing embedding ID: doc_148\n",
      "Insert of existing embedding ID: doc_149\n",
      "Add of existing embedding ID: doc_149\n",
      "Insert of existing embedding ID: doc_150\n",
      "Add of existing embedding ID: doc_150\n",
      "Insert of existing embedding ID: doc_151\n",
      "Add of existing embedding ID: doc_151\n",
      "Insert of existing embedding ID: doc_152\n",
      "Add of existing embedding ID: doc_152\n",
      "Insert of existing embedding ID: doc_153\n",
      "Add of existing embedding ID: doc_153\n",
      "Insert of existing embedding ID: doc_154\n",
      "Add of existing embedding ID: doc_154\n",
      "Insert of existing embedding ID: doc_155\n",
      "Add of existing embedding ID: doc_155\n",
      "Insert of existing embedding ID: doc_156\n",
      "Add of existing embedding ID: doc_156\n",
      "Insert of existing embedding ID: doc_157\n",
      "Add of existing embedding ID: doc_157\n",
      "Insert of existing embedding ID: doc_158\n",
      "Add of existing embedding ID: doc_158\n",
      "Insert of existing embedding ID: doc_159\n",
      "Add of existing embedding ID: doc_159\n",
      "Insert of existing embedding ID: doc_160\n",
      "Add of existing embedding ID: doc_160\n",
      "Insert of existing embedding ID: doc_161\n",
      "Add of existing embedding ID: doc_161\n",
      "Insert of existing embedding ID: doc_162\n",
      "Add of existing embedding ID: doc_162\n",
      "Insert of existing embedding ID: doc_163\n",
      "Add of existing embedding ID: doc_163\n",
      "Insert of existing embedding ID: doc_164\n",
      "Add of existing embedding ID: doc_164\n",
      "Insert of existing embedding ID: doc_165\n",
      "Add of existing embedding ID: doc_165\n",
      "Insert of existing embedding ID: doc_166\n",
      "Add of existing embedding ID: doc_166\n",
      "Insert of existing embedding ID: doc_167\n",
      "Add of existing embedding ID: doc_167\n",
      "Insert of existing embedding ID: doc_168\n",
      "Add of existing embedding ID: doc_168\n",
      "Insert of existing embedding ID: doc_169\n",
      "Add of existing embedding ID: doc_169\n",
      "Insert of existing embedding ID: doc_170\n",
      "Add of existing embedding ID: doc_170\n",
      "Insert of existing embedding ID: doc_171\n",
      "Add of existing embedding ID: doc_171\n",
      "Insert of existing embedding ID: doc_172\n",
      "Add of existing embedding ID: doc_172\n",
      "Insert of existing embedding ID: doc_173\n",
      "Add of existing embedding ID: doc_173\n",
      "Insert of existing embedding ID: doc_174\n",
      "Add of existing embedding ID: doc_174\n",
      "Insert of existing embedding ID: doc_175\n",
      "Add of existing embedding ID: doc_175\n",
      "Insert of existing embedding ID: doc_176\n",
      "Add of existing embedding ID: doc_176\n",
      "Insert of existing embedding ID: doc_177\n",
      "Add of existing embedding ID: doc_177\n",
      "Insert of existing embedding ID: doc_178\n",
      "Add of existing embedding ID: doc_178\n",
      "Insert of existing embedding ID: doc_179\n",
      "Add of existing embedding ID: doc_179\n",
      "Insert of existing embedding ID: doc_180\n",
      "Add of existing embedding ID: doc_180\n",
      "Insert of existing embedding ID: doc_181\n",
      "Add of existing embedding ID: doc_181\n",
      "Insert of existing embedding ID: doc_182\n",
      "Add of existing embedding ID: doc_182\n",
      "Insert of existing embedding ID: doc_183\n",
      "Add of existing embedding ID: doc_183\n",
      "Insert of existing embedding ID: doc_184\n",
      "Add of existing embedding ID: doc_184\n",
      "Insert of existing embedding ID: doc_185\n",
      "Add of existing embedding ID: doc_185\n",
      "Insert of existing embedding ID: doc_186\n",
      "Add of existing embedding ID: doc_186\n",
      "Insert of existing embedding ID: doc_187\n",
      "Add of existing embedding ID: doc_187\n",
      "Insert of existing embedding ID: doc_188\n",
      "Add of existing embedding ID: doc_188\n",
      "Insert of existing embedding ID: doc_189\n",
      "Add of existing embedding ID: doc_189\n",
      "Insert of existing embedding ID: doc_190\n",
      "Add of existing embedding ID: doc_190\n",
      "Insert of existing embedding ID: doc_191\n",
      "Add of existing embedding ID: doc_191\n",
      "Insert of existing embedding ID: doc_192\n",
      "Add of existing embedding ID: doc_192\n",
      "Insert of existing embedding ID: doc_193\n",
      "Add of existing embedding ID: doc_193\n",
      "Insert of existing embedding ID: doc_194\n",
      "Add of existing embedding ID: doc_194\n",
      "Insert of existing embedding ID: doc_195\n",
      "Add of existing embedding ID: doc_195\n",
      "Insert of existing embedding ID: doc_196\n",
      "Add of existing embedding ID: doc_196\n",
      "Insert of existing embedding ID: doc_197\n",
      "Add of existing embedding ID: doc_197\n",
      "Insert of existing embedding ID: doc_198\n",
      "Add of existing embedding ID: doc_198\n",
      "Insert of existing embedding ID: doc_199\n",
      "Add of existing embedding ID: doc_199\n",
      "Insert of existing embedding ID: doc_200\n",
      "Add of existing embedding ID: doc_200\n",
      "Insert of existing embedding ID: doc_201\n",
      "Add of existing embedding ID: doc_201\n",
      "Insert of existing embedding ID: doc_202\n",
      "Add of existing embedding ID: doc_202\n",
      "Insert of existing embedding ID: doc_203\n",
      "Add of existing embedding ID: doc_203\n",
      "Insert of existing embedding ID: doc_204\n",
      "Add of existing embedding ID: doc_204\n",
      "Insert of existing embedding ID: doc_205\n",
      "Add of existing embedding ID: doc_205\n",
      "Insert of existing embedding ID: doc_206\n",
      "Add of existing embedding ID: doc_206\n",
      "Insert of existing embedding ID: doc_207\n",
      "Add of existing embedding ID: doc_207\n",
      "Insert of existing embedding ID: doc_208\n",
      "Add of existing embedding ID: doc_208\n",
      "Insert of existing embedding ID: doc_209\n",
      "Add of existing embedding ID: doc_209\n",
      "Insert of existing embedding ID: doc_210\n",
      "Add of existing embedding ID: doc_210\n",
      "Insert of existing embedding ID: doc_211\n",
      "Add of existing embedding ID: doc_211\n",
      "Insert of existing embedding ID: doc_212\n",
      "Add of existing embedding ID: doc_212\n",
      "Insert of existing embedding ID: doc_213\n",
      "Add of existing embedding ID: doc_213\n",
      "Insert of existing embedding ID: doc_214\n",
      "Add of existing embedding ID: doc_214\n",
      "Insert of existing embedding ID: doc_215\n",
      "Add of existing embedding ID: doc_215\n",
      "Insert of existing embedding ID: doc_216\n",
      "Add of existing embedding ID: doc_216\n",
      "Insert of existing embedding ID: doc_217\n",
      "Add of existing embedding ID: doc_217\n",
      "Insert of existing embedding ID: doc_218\n",
      "Add of existing embedding ID: doc_218\n",
      "Insert of existing embedding ID: doc_219\n",
      "Add of existing embedding ID: doc_219\n",
      "Insert of existing embedding ID: doc_220\n",
      "Add of existing embedding ID: doc_220\n",
      "Insert of existing embedding ID: doc_221\n",
      "Add of existing embedding ID: doc_221\n",
      "Insert of existing embedding ID: doc_222\n",
      "Add of existing embedding ID: doc_222\n",
      "Insert of existing embedding ID: doc_223\n",
      "Add of existing embedding ID: doc_223\n",
      "Insert of existing embedding ID: doc_224\n",
      "Add of existing embedding ID: doc_224\n",
      "Insert of existing embedding ID: doc_225\n",
      "Add of existing embedding ID: doc_225\n",
      "Insert of existing embedding ID: doc_226\n",
      "Add of existing embedding ID: doc_226\n",
      "Insert of existing embedding ID: doc_227\n",
      "Add of existing embedding ID: doc_227\n",
      "Insert of existing embedding ID: doc_228\n",
      "Add of existing embedding ID: doc_228\n",
      "Insert of existing embedding ID: doc_229\n",
      "Add of existing embedding ID: doc_229\n",
      "Insert of existing embedding ID: doc_230\n",
      "Add of existing embedding ID: doc_230\n",
      "Insert of existing embedding ID: doc_231\n",
      "Add of existing embedding ID: doc_231\n",
      "Insert of existing embedding ID: doc_232\n",
      "Add of existing embedding ID: doc_232\n",
      "Insert of existing embedding ID: doc_233\n",
      "Add of existing embedding ID: doc_233\n",
      "Insert of existing embedding ID: doc_234\n",
      "Add of existing embedding ID: doc_234\n",
      "Insert of existing embedding ID: doc_235\n",
      "Add of existing embedding ID: doc_235\n",
      "Insert of existing embedding ID: doc_236\n",
      "Add of existing embedding ID: doc_236\n",
      "Insert of existing embedding ID: doc_237\n",
      "Add of existing embedding ID: doc_237\n",
      "Insert of existing embedding ID: doc_238\n",
      "Add of existing embedding ID: doc_238\n",
      "Insert of existing embedding ID: doc_239\n",
      "Add of existing embedding ID: doc_239\n",
      "Insert of existing embedding ID: doc_240\n",
      "Add of existing embedding ID: doc_240\n",
      "Insert of existing embedding ID: doc_241\n",
      "Add of existing embedding ID: doc_241\n",
      "Insert of existing embedding ID: doc_242\n",
      "Add of existing embedding ID: doc_242\n",
      "Insert of existing embedding ID: doc_243\n",
      "Add of existing embedding ID: doc_243\n",
      "Insert of existing embedding ID: doc_244\n",
      "Add of existing embedding ID: doc_244\n",
      "Insert of existing embedding ID: doc_245\n",
      "Add of existing embedding ID: doc_245\n",
      "Insert of existing embedding ID: doc_246\n",
      "Add of existing embedding ID: doc_246\n",
      "Insert of existing embedding ID: doc_247\n",
      "Add of existing embedding ID: doc_247\n",
      "Insert of existing embedding ID: doc_248\n",
      "Add of existing embedding ID: doc_248\n",
      "Insert of existing embedding ID: doc_249\n",
      "Add of existing embedding ID: doc_249\n",
      "Insert of existing embedding ID: doc_250\n",
      "Add of existing embedding ID: doc_250\n",
      "Insert of existing embedding ID: doc_251\n",
      "Add of existing embedding ID: doc_251\n",
      "Insert of existing embedding ID: doc_252\n",
      "Add of existing embedding ID: doc_252\n",
      "Insert of existing embedding ID: doc_253\n",
      "Add of existing embedding ID: doc_253\n",
      "Insert of existing embedding ID: doc_254\n",
      "Add of existing embedding ID: doc_254\n",
      "Insert of existing embedding ID: doc_255\n",
      "Add of existing embedding ID: doc_255\n",
      "Insert of existing embedding ID: doc_256\n",
      "Add of existing embedding ID: doc_256\n",
      "Insert of existing embedding ID: doc_257\n",
      "Add of existing embedding ID: doc_257\n",
      "Insert of existing embedding ID: doc_258\n",
      "Add of existing embedding ID: doc_258\n",
      "Insert of existing embedding ID: doc_259\n",
      "Add of existing embedding ID: doc_259\n",
      "Insert of existing embedding ID: doc_260\n",
      "Add of existing embedding ID: doc_260\n",
      "Insert of existing embedding ID: doc_261\n",
      "Add of existing embedding ID: doc_261\n",
      "Insert of existing embedding ID: doc_262\n",
      "Add of existing embedding ID: doc_262\n",
      "Insert of existing embedding ID: doc_263\n",
      "Add of existing embedding ID: doc_263\n",
      "Insert of existing embedding ID: doc_264\n",
      "Add of existing embedding ID: doc_264\n",
      "Insert of existing embedding ID: doc_265\n",
      "Add of existing embedding ID: doc_265\n",
      "Insert of existing embedding ID: doc_266\n",
      "Add of existing embedding ID: doc_266\n",
      "Insert of existing embedding ID: doc_267\n",
      "Add of existing embedding ID: doc_267\n",
      "Insert of existing embedding ID: doc_268\n",
      "Add of existing embedding ID: doc_268\n",
      "Insert of existing embedding ID: doc_269\n",
      "Add of existing embedding ID: doc_269\n",
      "Insert of existing embedding ID: doc_270\n",
      "Add of existing embedding ID: doc_270\n",
      "Insert of existing embedding ID: doc_271\n",
      "Add of existing embedding ID: doc_271\n",
      "Insert of existing embedding ID: doc_272\n",
      "Add of existing embedding ID: doc_272\n",
      "Insert of existing embedding ID: doc_273\n",
      "Add of existing embedding ID: doc_273\n",
      "Insert of existing embedding ID: doc_274\n",
      "Add of existing embedding ID: doc_274\n",
      "Insert of existing embedding ID: doc_275\n",
      "Add of existing embedding ID: doc_275\n",
      "Insert of existing embedding ID: doc_276\n",
      "Add of existing embedding ID: doc_276\n",
      "Insert of existing embedding ID: doc_277\n",
      "Add of existing embedding ID: doc_277\n",
      "Insert of existing embedding ID: doc_278\n",
      "Add of existing embedding ID: doc_278\n",
      "Insert of existing embedding ID: doc_279\n",
      "Add of existing embedding ID: doc_279\n",
      "Insert of existing embedding ID: doc_280\n",
      "Add of existing embedding ID: doc_280\n",
      "Insert of existing embedding ID: doc_281\n",
      "Add of existing embedding ID: doc_281\n",
      "Insert of existing embedding ID: doc_282\n",
      "Add of existing embedding ID: doc_282\n",
      "Insert of existing embedding ID: doc_283\n",
      "Add of existing embedding ID: doc_283\n",
      "Insert of existing embedding ID: doc_284\n",
      "Add of existing embedding ID: doc_284\n",
      "Insert of existing embedding ID: doc_285\n",
      "Add of existing embedding ID: doc_285\n",
      "Insert of existing embedding ID: doc_286\n",
      "Add of existing embedding ID: doc_286\n",
      "Insert of existing embedding ID: doc_287\n",
      "Add of existing embedding ID: doc_287\n",
      "Insert of existing embedding ID: doc_288\n",
      "Add of existing embedding ID: doc_288\n",
      "Insert of existing embedding ID: doc_289\n",
      "Add of existing embedding ID: doc_289\n",
      "Insert of existing embedding ID: doc_290\n",
      "Add of existing embedding ID: doc_290\n",
      "Insert of existing embedding ID: doc_291\n",
      "Add of existing embedding ID: doc_291\n",
      "Insert of existing embedding ID: doc_292\n",
      "Add of existing embedding ID: doc_292\n",
      "Insert of existing embedding ID: doc_293\n",
      "Add of existing embedding ID: doc_293\n",
      "Insert of existing embedding ID: doc_294\n",
      "Add of existing embedding ID: doc_294\n",
      "Insert of existing embedding ID: doc_295\n",
      "Add of existing embedding ID: doc_295\n",
      "Insert of existing embedding ID: doc_296\n",
      "Add of existing embedding ID: doc_296\n",
      "Insert of existing embedding ID: doc_297\n",
      "Add of existing embedding ID: doc_297\n",
      "Insert of existing embedding ID: doc_298\n",
      "Add of existing embedding ID: doc_298\n",
      "Insert of existing embedding ID: doc_299\n",
      "Add of existing embedding ID: doc_299\n",
      "Insert of existing embedding ID: doc_300\n",
      "Add of existing embedding ID: doc_300\n",
      "Insert of existing embedding ID: doc_301\n",
      "Add of existing embedding ID: doc_301\n",
      "Insert of existing embedding ID: doc_302\n",
      "Add of existing embedding ID: doc_302\n",
      "Insert of existing embedding ID: doc_303\n",
      "Add of existing embedding ID: doc_303\n",
      "Insert of existing embedding ID: doc_304\n",
      "Add of existing embedding ID: doc_304\n",
      "Insert of existing embedding ID: doc_305\n",
      "Add of existing embedding ID: doc_305\n",
      "Insert of existing embedding ID: doc_306\n",
      "Add of existing embedding ID: doc_306\n",
      "Insert of existing embedding ID: doc_307\n",
      "Add of existing embedding ID: doc_307\n",
      "Insert of existing embedding ID: doc_308\n",
      "Add of existing embedding ID: doc_308\n",
      "Insert of existing embedding ID: doc_309\n",
      "Add of existing embedding ID: doc_309\n",
      "Insert of existing embedding ID: doc_310\n",
      "Add of existing embedding ID: doc_310\n",
      "Insert of existing embedding ID: doc_311\n",
      "Add of existing embedding ID: doc_311\n",
      "Insert of existing embedding ID: doc_312\n",
      "Add of existing embedding ID: doc_312\n",
      "Insert of existing embedding ID: doc_313\n",
      "Add of existing embedding ID: doc_313\n",
      "Insert of existing embedding ID: doc_314\n",
      "Add of existing embedding ID: doc_314\n",
      "Insert of existing embedding ID: doc_315\n",
      "Add of existing embedding ID: doc_315\n",
      "Insert of existing embedding ID: doc_316\n",
      "Add of existing embedding ID: doc_316\n",
      "Insert of existing embedding ID: doc_317\n",
      "Add of existing embedding ID: doc_317\n",
      "Insert of existing embedding ID: doc_318\n",
      "Add of existing embedding ID: doc_318\n",
      "Insert of existing embedding ID: doc_319\n",
      "Add of existing embedding ID: doc_319\n",
      "Insert of existing embedding ID: doc_320\n",
      "Add of existing embedding ID: doc_320\n",
      "Insert of existing embedding ID: doc_321\n",
      "Add of existing embedding ID: doc_321\n",
      "Insert of existing embedding ID: doc_322\n",
      "Add of existing embedding ID: doc_322\n",
      "Insert of existing embedding ID: doc_323\n",
      "Add of existing embedding ID: doc_323\n",
      "Insert of existing embedding ID: doc_324\n",
      "Add of existing embedding ID: doc_324\n",
      "Insert of existing embedding ID: doc_325\n",
      "Add of existing embedding ID: doc_325\n",
      "Insert of existing embedding ID: doc_326\n",
      "Add of existing embedding ID: doc_326\n",
      "Insert of existing embedding ID: doc_327\n",
      "Add of existing embedding ID: doc_327\n",
      "Insert of existing embedding ID: doc_328\n",
      "Add of existing embedding ID: doc_328\n",
      "Insert of existing embedding ID: doc_329\n",
      "Add of existing embedding ID: doc_329\n",
      "Insert of existing embedding ID: doc_330\n",
      "Add of existing embedding ID: doc_330\n",
      "Insert of existing embedding ID: doc_331\n",
      "Add of existing embedding ID: doc_331\n",
      "Insert of existing embedding ID: doc_332\n",
      "Add of existing embedding ID: doc_332\n",
      "Insert of existing embedding ID: doc_333\n",
      "Add of existing embedding ID: doc_333\n",
      "Insert of existing embedding ID: doc_334\n",
      "Add of existing embedding ID: doc_334\n",
      "Insert of existing embedding ID: doc_335\n",
      "Add of existing embedding ID: doc_335\n",
      "Insert of existing embedding ID: doc_336\n",
      "Add of existing embedding ID: doc_336\n",
      "Insert of existing embedding ID: doc_337\n",
      "Add of existing embedding ID: doc_337\n",
      "Insert of existing embedding ID: doc_338\n",
      "Add of existing embedding ID: doc_338\n",
      "Insert of existing embedding ID: doc_339\n",
      "Add of existing embedding ID: doc_339\n",
      "Insert of existing embedding ID: doc_340\n",
      "Add of existing embedding ID: doc_340\n",
      "Insert of existing embedding ID: doc_341\n",
      "Add of existing embedding ID: doc_341\n",
      "Insert of existing embedding ID: doc_342\n",
      "Add of existing embedding ID: doc_342\n",
      "Insert of existing embedding ID: doc_343\n",
      "Add of existing embedding ID: doc_343\n",
      "Insert of existing embedding ID: doc_344\n",
      "Add of existing embedding ID: doc_344\n",
      "Insert of existing embedding ID: doc_345\n",
      "Add of existing embedding ID: doc_345\n",
      "Insert of existing embedding ID: doc_346\n",
      "Add of existing embedding ID: doc_346\n",
      "Insert of existing embedding ID: doc_347\n",
      "Add of existing embedding ID: doc_347\n"
     ]
    }
   ],
   "source": [
    "collection = client.get_or_create_collection(\n",
    "        name=\"aws_blogs\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "datasets_dir = \"../dataset/aws-case-studies-blogs-dataset\" \n",
    "add_text_files_to_collection(collection, datasets_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d0b76f-af74-42e3-ae31-80247cc05a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"tell me about aws lambda\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[query_string],\n",
    "    n_results=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8787d27b-4a7c-40f9-bcc8-77f118707a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In addition to better compliance with regulations through improved transparency, the Purple IT team has improved and accelerated software development processes using AWS.\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers. You can trigger Lambda from over 200 AWS services and software as a service (SaaS) applications, and only pay for what you use.File processing\\xa0Stream processing\\xa0Web applications\\xa0IoT backends\\xa0Mobile backends.  \\nFranais\\n Benefits of AWS\\nJan ervinka Director of Engineering, Purple Technology \\nEspaol\\n Amazon EC2\\nThe Czech-based company builds apps that complement online trading platforms and support the changing and demanding needs of brokers. Purples solution enables tens of thousands of clients to trade many billions of dollars of assets each month.\\n\\nIn addition, brokers and traders must comply with rules that change from country to country. These rules are subject to sudden changes in regulationand even to evolving legal interpretations.\\n Get Started\\n\\nAmazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. DynamoDB offers built-in security, continuous backups, automated multi-Region replication, in-memory caching, and data import and export tools. \\nIncreases transparency of complex processes\\n Purple Technology Responds Rapidly to Changing Regulations and Customer Needs Using AWS\\n \\n Amazon Lambda\\nPurple needed a more transparent and effective way to manage the complex ruleset that governed customer onboarding and allow it to respond more quickly to changing rules. It found the solution it needed using AWS Step Functions, a low-code, visual workflow service that developers can use to build applications. Onboarding involves complex processes that we have to be able to understand and update easily, says Jan ervinka, director of engineering at Purple Technology. We can now map and design all of these processes using AWS Step Functions.\\nTo register new trading accounts with brokers, users need to go through a number of steps to qualify. The registration process checks many conditions, some via API, to confirm that the new customer is not disqualified from trading. Purples onboarding process also supports Know Your Customer (KYC) user verification and anti-money laundering (AML) processes.\\n Amazon Step functions\\n AWS Services Used\\nPurple wanted greater transparency and control to improve its services and reduce the in-house resources required to maintain its applications. Using Amazon Web Services (AWS), Purple found a way to easily manage changes to the backend ruleset and make the ruleset more transparent to internal and external stakeholders.\\n ()\\nBahasa Indonesia\\nWhile the Purple application has a user-friendly front end, the backend was a complex code base. Changes to the rules required developers to delve into the code to make amendments and make sure the app was compliant. Questions from product managers about the rules and processes required developers to create diagrams that would quickly become outdated.\\n  Contact Sales \\n\\n\\n ()\\nTo simplify this maintenance process further, Purple built a Slack extension to allow rules to be repaired and amended from the messaging platform. This also means customer service teams at brokers can operate the tool and provide a responsive service to their own customers. Using AWS we have significantly improved the self-service capabilities of the customer support teams, says ervinka. That leads to a much faster time to resolution of certain issues customers may encounter.\\n About Purple Technology \\nLearn more\\xa0\\nBuild and run applications without thinking about servers.\\xa0Severless on AWS \\nResponding to Changing Regulatory Changes\\nOn AWS, Purple also has greater freedom to innovate. Using AWS infrastructure as code means that developers can spin up test environments to work on new features. These test environments consume fewer resources than production sites. Using AWS we can experiment and play with new ideas. And we have the confidence that we can stay on top of the changes to regulations through better control and transparency with AWS services, says Prek. \\nUsing AWS Step Functions, the company always has up-to-date product documentation as it is automatically generated. Now if a regulator or legal counsel asks to review the applications processes, Purple can share the documentation to demonstrate how it complies. Its much easier to produce visual reports and diagrams for our compliance stakeholders, says ervinka. That frees up IT teams from having to provide complex, time-intensiveand not really funsupport so they can instead focus on building new features.\\nReduces maintenance burden on developer team\\nTrke\\nFinTech company Purple Technology builds applications and services for brokerage firms to onboard customers efficiently. End users self-manage their accounts and portfolios, which leaves brokerages free to focus on core functions such as client services and risk management. Users creating new trading accounts with brokers need to follow a stringent onboarding process that complies with complex rules and regulations to verify their identities. Using AWS, Purple has simplified the way these rulesets are coded into the app, making it easier for non-technical employees to manage the application and keep on top of changing regulations. \\nEnglish\\nBut managing those rules was a complex and time-consuming process, often requiring developer resources that would be better spent on product innovation, not maintenance.\\nResolves software issues more efficiently\\nAmazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.\\nDevelopers can also devote more time to improving the platform rather than troubleshooting issues, because AWS Step Functions has reduced the time required for debugging. This has increased the teams speed of development.\\nDeutsch\\n Amazon DynamoDB\\nTrading and investing online relies on transparency, and trust in the platform, in the brokers, and in the identity of traders. Purple Technology helps build that trust.\\nTing Vit\\nItaliano\\n\\nUsing AWS, we have greater visibility into our complex processes, making them simple to visualize, manage, and update. This means we can be more responsive to any new or changing regulations and to customer needs. \\nBoosts speed of development of new features \\nCommunication with business decision-makers on new software features is now more productive. Its easy to read and modify AWS Step Functions, says Filip Prek, serverless architect at Purple Technology. We use it for prototyping when designing features, so non-technical colleagues can understand and discuss new processes.\\n2022\\nBased in the Czech Republic, Purple Technology is a financial technology company founded in 2011. It provides an online trading platform for brokerages and their clients around the world. \\n Faster Development and Product Maintenance\\nAs a FinTech company, Purples solution has to comply with a huge number of legal and regulatory rules that vary from territory to territory and are subject to constant change. Purples solution needs to accurately capture these rules to run checks during new trader account registrations.\\nAWS Step Functions is a low-code, visual workflow service that developers use to build distributed applications, automate IT and business processes, and build data and machine learning pipelines using AWS services. Workflows manage failures, retries, parallelization, service integrations, and observability so developers can focus on higher-value business logic.  \\nPortugus\\nUsing AWS Step Functions, Purple Technology maps out the workflows for each process so that it can easily fix any issues and demonstrate to regulators how customer checks are carried out. In addition, rather than drawing on developers to make changes, Purple can use trained, non-technical people to carry out maintenance.\\n10\\n AWS Lambda\\nConfiguring Cloud Environments 3x Faster\\nFranais\\nSpacelift supports customers working in pure cloud environments as well as those running hybrid models because they need to store certain data on premises to comply with security or privacy regulations.\\nCut down on security and compliance issues by a factor of 10 \\nEspaol\\nThis means customers require fewer senior-level IT staff or can increase productivity of current developers, so they have more time to create innovative products and features. When new developers join a company, they can spin up all the infrastructure they need in seconds with little product knowledge, and then quickly minimize error risks and correct any misconfigurations, says Wyszynski. Through automation, our customers DevOps teams can configure cloud environments 3 times faster than doing the same work manually.\\n 90%\\nTo ensure that its platform is flexible and able to scale rapidly, Spacelift uses AWS Lambda, which allows users to run code without thinking about servers or clusters. This helps the company deal with unpredictable workload demand from customers. A single customer might launch a thousand tasks that need addressing, and then have nothing to process for the next hour, says Kuba Martin, software engineer at Spacelift. Using AWS Lambda, we can quickly spin up compute capacity to deal with incoming requests, so they can be resolved quickly and tasks dont accumulate. This means our customers experience reliable performanceand they stay happy.  \\nEasing Communication for Hybrid Environments Using AWS IoT Core \\nDevelopers working for Spacelifts customers can set up cloud environments immediately, even if they have minimal cloud experience, because Spacelift provides an easy-to-use interface to the underlying AWS setup.\\n\\n  Contact Sales \\n 2022\\nSpacelift Reduces Time Spent on Cloud Management by 90% Using AWS\\n\\nSped up cloud environments configurations by 300% \\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\nThis reduces the complexity of the infrastructure so it can be managed with fewer DevOps engineers. It also means that new environments needed for startups or a large company opening a new office, for instance, can be set up quickly, easing corporate expansions. Automation also reduces the error rates compared to manual configurations, so its customers platforms are more reliable for their end customers.\\n \\nBased in Silicon Valley and Poland, Spacelift has created a platform that simplifies the management of complex cloud environments. That means IT teams can focus on creating innovative products, rather than maintaining infrastructure. The approach has proved popular and spurred the companys growth from 1 to 40 employees over 2 years.\\nTo ensure high levels of reliability, security, and compliance for its platform, Spacelift turned to Amazon Web Services (AWS). Using AWS, the start-up has helped customers such as Checkout.com and Kin cut down on the time spent on repetitive infrastructure maintenance tasks by 90 percent. For example, by automating security and data privacy configurations, the company has reduced the time needed to handle these issues by a factor of 10 compared to doing the work manually. \\n Get Started\\nSpacelift is now part of AWS ISV Accelerate, a co-sell program for organizations that provide software solutions that run on, or integrate with, AWS. Its solution is also available for businesses to download and deploy from AWS Marketplace. Were always looking to deepen our use of AWS, says Wyszynski. Working together closely helps us to build on our success and supports ongoing product development, meaning we can continually improve our services for customers.  \\nGetting Up and Running on AWS in Half the Expected Time\\n AWS Activate\\n AWS Services Used\\nAWS Activate provides startups with a host of benefits, including AWS credits*, AWS support plan credits, and architecture guidance to help grow your business.  Learn more\\xa0\\n ()\\nBahasa Indonesia\\n Spacelift Reduces Time Spent on Cloud Management by 90% Using AWS\\nSpacelifts platform combines continuous integration and deployment (CI/CD) processes to manage infrastructure as code (IaC), so customers can easily and quickly set up and maintain cloud architectures. Using the Spacelift platform, customers can replicate code with common open-source IaC tools instead of configuring new cloud environments manually. \\n\\nCustomer Stories / Software & Internet \\n\\nSpacelift also cuts down on the time required from developer teams to fix code issues when replicating code. Using AWS, we can simply roll back to a reset with just 3 clicks and minimize the engineers involvement, if there are any code errors, says Wyszynski. This is one of the biggest advantages of having a highly available system.\\nMarcin Wyszynski,  Founder and Chief Product Officer, Spacelift \\n ()\\nReduced customers repetitive development tasks by 90% \\nTo facilitate information flow between the cloud and the on-premises system, Spacelift uses AWS IoT Core, which easily and securely connects devices to the cloud. With a direct cloud connection to a customers IT environment, we can easily route communications, says Wyszynski. This helps to keep the technical complexity of the platform low and means the client doesnt have to worry about managing additional infrastructure.\\n AWS IoT Core\\n 300%\\n Overview\\n About Company\\nBuilt platform on AWS in 4 monthshalf the expected time \\nWeve moved so fast thanks to help from the AWS support teams and the AWS Activate program. We were able to quickly verify product assumptions and the support team helped us to get key functionalities right. \\nTrke\\nEnglish\\nSpacelift helps businesses to easily set up and manage complex cloud environments, so they can do more with fewer team members. Its platform combines continuous integration and deployment (CI/CD) processes to manage infrastructure as code (IaC). This speeds up code development, and increases the efficiency of workflow management by reducing error rates and automating key manual tasks. Using AWS, Spacelift has helped customers like Checkout.com and Kin to cut down on repetitive infrastructure maintenance tasks by 90 percent. Automating security and data privacy configurations means customers reduce the time spent on these issues by a factor of 10. \\nAlmost half of IT recruiters worldwide report difficulties in finding qualified developer candidates. Fast-growing startup Spacelift addresses this shortage of technical staff by helping businesses do more with the DevOps and engineering talent they have.\\n 4 months\\nThe AWS ISV Accelerate Program is a co-sell program for organizations that provide software solutions that run on or integrate with AWS.  Learn more\\xa0\\nThe company built its system on AWS from day one, and was up and running in just 4 months, twice as fast as it had estimated it would take. We moved so quickly thanks to help from the AWS support teams and the AWS Activate program, says Marcin Wyszynski, founder and chief product officer at Spacelift. We were able to quickly verify product assumptions and the support team helped us to get key functionalities right.\\nDeutsch\\nSpacelift helps businesses to easily set up and manage complex cloud environments, so they can do more with fewer team members. Its platform combines continuous integration and deployment (CI/CD) processes to manage infrastructure as code (IaC). \\nTing Vit\\nSpacelift offers a collaborative platform to manage cloud infrastructures and services. Its platform uses continuous integration and deployment (CI/CD) processes and supports infrastructure as code management tools to speed runtime configuration, version management, and state management. It has 40 employees and is based in Poland and the US.  \\nItaliano\\n\\n AWS ISV Accelerate\\nAWS IoT Core lets you connect billions of IoT devices and route trillions of messages to AWS services without managing infrastructure.Message Broker\\xa0Mirror Device State\\xa0Built-in Alexa\\xa0LoRaWAN Devices.  Learn more\\xa0\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers.  Learn more\\xa0 \\nSpacelift chose AWS to ensure ease of use for its customers, as the majority of them were already using AWS. All of our customers use AWS in a sophisticated way, so the fact that we use the same technologies and tools means its easy for them to get set up with our platform too, says Wyszynski. \\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nPortugus\\nAWS Lambda\\nOutcome | Continuing to Modernize and Improve Using AWS \\nFranais\\nCapital One is still in the process of modernizing its applications, and going serverless is not where this modernization will end. The company plans to become as cloud native as possible and is potentially looking to shift its extract, transform, and load jobs to AWS Lambda. Capital One recently adopted AWS Glue, a serverless data integration service used to discover, prepare, move, and integrate data from multiple sources, and at the same time, evaluated other new serverless options, such as AWS Step Functions, visual workflows for distributed applications, alongside AWS Lambda. Any organization thats committed to its technical transformation should work alongside the AWS team to go in the right direction, says Mao. \\n           2023 \\nAnother benefit of going serverless is the improved cost efficiency. By migrating to AWS Lambda, Capital One hopes to improve its costs. It can achieve this in part by saving developer time. If we can save developers time by reducing infrastructure-related work, that savings is enormous, says Mao. The other cost-efficiency factor is AWS Lambdas pay-as-you-use model. The company pays at a per-millisecond interval for compute costs. The cost efficiency is awesome. It changes the way that we think about building applications, says Mao. Using AWS Lambda, our engineers learn to build small and think about performance. One application achieved 90 percent cost savings by migrating to AWS Lambda.\\nEspaol\\nLearn more \\ncost savings for applications \\n\\n AWS Services Used\\n Capital One Saves Developer Time and Reduces Costs by Going Serverless on AWS\\n Get Started\\n\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\n AWS SAM\\n \\n Improved\\n         \\nSolution | Improving Speed to Market and Reducing Costs Using AWS Serverless Technologies \\nGeorge Mao\\x0b Senior Distinguished Engineer, Capital One Financial Corporation \\n Amazon ECS\\n Overview\\n ()\\nBahasa Indonesia\\nOpportunity | Using AWS Lambda to Save Developer Time for Capital One \\nMany Capital One applications run once a day, and others run once a month, which makes leaving instances up all the time inefficient. When we migrate to AWS Lambda, our teams dont have to worry about whether to scale instances up or down, says Mao. The same batch process that runs 1 or 100 times a day runs on AWS Lambda. Developers can spend their time and effort making better products for the customers rather than worrying about managing or operating the infrastructure. The company is making better applications and delivering more features faster with a quicker time to market. All the things that make the cloud great are enhanced by going serverless, which is a win-win for us and our customers, says Mao.\\nCapital One Financial Corporation (Capital One) exited its last legacy, on-premises data centers in 2020 to go all in on the cloud. Capital One has strict timelines for code patches, machine refreshes, and bug remediation. Its engineers, who would prefer to be building applications, were spending significant time working on infrastructure. Capital One improved its cost efficiency, speed to market, and developer quality of life by using Amazon Web Services (AWS) such as AWS Lambdaa serverless, event-driven compute service that businesses use to run code for virtually any type of application or backend service without provisioning or managing servers. The company is now achieving significant time savings for its developers in applications that are migrated to serverless compute while remaining well governed. \\n\\nAny organization thats committed to its technical transformation should work alongside the AWS team to go in the right direction. \\n\\n ()\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nThis strategy has resulted in a large shift in the developer mindset and tooling process for the companymigrating away from a monolithic infrastructure and toward the building of smaller applications with higher-quality performance. During this digital transformation, the company has benefited from directly communicating with AWS service specialists for near-real-time support when it has production outages and service issues. We treat the AWS account team as an extension of our internal architecture teams and communicate with the team daily to handle service issues and get updates quickly, says Mao.\\nLearn how Capital One in financial services saved developer time and reduced cost by going serverless using AWS Lambda and Amazon ECS. \\nLearn more\\xa0\\noperational efficency \\n\\xa0\\n Up to 90%\\nWith its applications running in various states of monolithic and modern architectures, Capital Ones default strategy is to migrate its applications to serverless compute, where it can reduce the overall operational burden for its engineering teams and increase operational efficiency. This migration helped the company ease the challenges that are associated with legacy architectures by reducing idle times and improving local debugging. For use cases when AWS Lambda cannot be used, the company uses Amazon Elastic Container Service (Amazon ECS)which runs highly secure, reliable, and scalable containerspowered by AWS Fargate, a serverless, pay-as-you-go compute engine that is used to build applications without managing servers.\\n AWS Fargate\\nCustomer Stories / Financial Services \\nThe companys engineers use a central pipeline that has been upgraded to adapt to serverless computing to release code. To reduce the idle time that its engineers have to spend waiting for releases to go through this pipeline, Capital One uses the AWS Serverless Application Model (AWS SAM), an open-source framework for building serverless applications that provides shorthand syntax to express functions, APIs, databases, and event source mappings. By using AWS SAM, its engineers can run as much as possible locally before touching the release pipeline. Capital One has adapted its tooling and release process to deploy tens of thousands of AWS Lambda functions. We can get what we need out of standard tooling like AWS SAM, says Mao.\\nnew applications in days \\nTrke\\nEnglish\\nAWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. \\nAmazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service that makes it easy for you to deploy, manage, and scale containerized applications.\\nThe AWS Serverless Application Model (SAM) is an open-source framework for building serverless applications.. \\n Saved\\n About Capital One Financial Corporation\\n Built\\nDeutsch\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers.  \\nBy migrating its applications to serverless services like AWS Lambda, Capital One has achieved significant time savings across different developer teams. This saved time translates directly into an improved speed to market. Migrating its old applications to AWS Lambda could take weeks to months, depending on the underlying architecture of the application. For new applications, some teams at the company have put together a working application in days.\\nTing Vit\\nCapital One is one of the top 10 largest banks in the United States, providing its banking and credit card services to its customers since 1994. The technical organization within the company has more than 12,000 people, the majority of whom are engineers. In 2020, the company closed its last physical data center and migrated everything to AWS. Since then, weve made the decision to go serverless whenever possible, says George Mao, senior distinguished engineer at Capital One. Most of our technical organization is focused on modernizing our entire offering of applications. As of the end of 2022, more than a third of Capital Ones apps use serverless technology.\\nItaliano\\n\\n  Contact Sales \\nsignificant time for developers \\nCapital One Financial Corporation is one of the top 10 largest banks in the United States and has been providing banking and credit card services since its founding in 1994. \\nPortugus\\nLambdaTest is a cloud-based continuous quality testing platform that helps over 2 million developers and testers across 130+ countries ship code faster. To give customers quicker, better insights into software test results, the company worked with AWS Data Lab to build a new analytical dashboard solution on Amazon Redshift.\\nFranais\\nresponse times for faster insights\\n           2023 \\nMore than two million software developers and testers across the globe rely on LambdaTest, a continuous quality testing platform, to ensure quality code and ship their software to customers faster. The platform, which runs on Amazon Web Services (AWS), provides both manual and automated testing of web and mobile apps across more than 3000 different browsers, mobile devices, and operating systems. LambdaTest is used in over 130 countries and has hosted more than 200 million tests to date.\\n About LambdaTest\\nEspaol\\nBy implementing its new analytics platform on Amazon Redshift, LambdaTest has reduced the average response time by 33 percent, updating analytical dashboards in less than 10 seconds. Using the federated query capability in Amazon Redshift, our customers have less than 50 millisecond response times for their test analysis dashboards and an average data refresh cycle of less than five minutes, says Rahman. This means they can get faster insights into test orchestration and execution and can easily see if tests fail. Overall, Amazon Redshift helps us give our customers better, faster insights into software test performance.\\n Learn More\\n\\ncustomers served\\nOpportunity | Seeking a Better View of Software Test Results\\n Get Started\\n\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\n \\nThe new dashboard, which LambdaTest designed and implemented in just 4 weeks, reduces dashboard response times by 33 percent and gives customers faster insights into test orchestration and execution results.\\xa0 \\nThe LambdaTest analytical platform on AWS can also scale seamlessly to support the ingestion of millions of data records annually. Amazon Redshift is highly scalable, especially when were doing federated queries and ingesting data from Amazon RDS instances, says Srivishnu Ayyagari, senior product manager at LambdaTest. Even when more data comes onto our analytical platform, it continues to perform at a high level.\\n         \\n Amazon Redshift\\nreduction in dashboard response time \\n AWS Services Used\\nOutcome | Reducing Response Time and Improving Test Insights\\n ()\\nBahasa Indonesia\\nfrom POC to production \\n LambdaTest Improves Software Test Insights and Cuts Dashboard Response Time by 33% Using Amazon Redshift\\n\\nCustomer Stories / Software & Internet \\n\\n ()\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nAWS Data Lab offers accelerated, joint engineering engagements between customers and AWS technical resources to create tangible deliverables that accelerate data and analytics modernization initiatives.  Learn more\\xa0\\n 4 weeks\\nFor the past several years, LambdaTests enterprise clients have been seeking analytical dashboards where they can quickly view insights and reports on test orchestration, execution, and results. Our customers didnt have a snapshot view of what tests had been run or what had failed, says SS Rahman, head of technical integration at LambdaTest. To address this, the company attempted to build a new analytics solution with MySQL as the data source. However, database queries often took up to 15 seconds to complete, and the solution couldnt meet the companys goal of providing response times under 10 seconds. The result? A poor customer experience, and one that could not scale easily to support the millions of new records coming in every year.\\xa0\\n Overview\\nThe solution is based on Amazon Redshift, a cloud data warehouse that uses SQL to analyze both structured and semi-structured data. The AWS team helped LambdaTest create a proof of concept (POC) for a new customer-facing dashboard that queries data from Amazon Relational Database Service (Amazon RDS) and ingests it in Amazon Redshift. The test metadata includes pass, failure, and completion information for each test. The dashboards also feature a variety of trend graphs and charts to visualize the distribution of test results among browsers, operating systems, and apps.\\nAmazon Redshift uses SQL to analyze structured and semi-structured data across data warehouses, operational databases, and data lakes, using AWS-designed hardware and machine learning to deliver the best price performance at any scale. \\nTrke\\nEnglish\\nLambdaTest utilized Amazon Redshift to build new dashboards that reduce dashboard response times by up to 33 percent and give customers faster software test insights. \\nWorking with the AWS Data Lab team, LambdaTest completed the dashboard POC in four weeks. If we managed this project on our own instead of relying heavily on the expertise of AWS, we would have taken at least eight weeks, says Rahman.\\xa0\\nSS Rahman Head of Technical Integration, LambdaTest \\n 1 million\\nDeutsch\\nLambdaTest, based in San Francisco, California, is a continuous quality testing cloud platform that helps more than 2 million developers and testers across 130+ countries ship code faster. The companys browser and app testing cloud runs manual and automated tests of web and mobile apps across 3,000+ environments including browsers, real devices, and multiple operating systems.\\xa0 \\nTo design a new analytical dashboard solution, LambdaTest leveraged the AWS Data Lab program, an internal AWS community that offers technical resources and hands-on support for customers looking to accelerate data and analytics initiatives. Specifically, LambdaTest participated in the AWS Build Lab, an intensive multi-day engagement in which AWS Data Lab Solutions Architects and other AWS experts provide architectural guidance, share best practices, and remove technical roadblocks. AWS has always been very available and helpful. When we discussed our latency and performance issues during the AWS Build Lab, AWS proposed the perfect solution, Rahman says.\\nTing Vit\\nItaliano\\n\\nLambdaTest is currently implementing Amazon OpenSearch Service to manage data log analytics in the cloud. AWS releases new services frequently, and we always evaluate those services for our business, Rahman says. Were a growing company focused on innovating in the testing space, and we will continue to work together with AWS as we expand.\\n 50 milliseconds\\nUsing the federated query capability in Amazon Redshift, our customers have less than 50 millisecond response times for their test analysis dashboards and an average data refresh cycle of less than five minutes. This means they can get faster insights into test orchestration and execution, and they can easily see if tests fail.\\nLearn more\\xa0\\n AWS Data Lab\\nSolution | Working with AWS Data Lab to Build a New Analytical Dashboard\\n 33%\\nTo learn more, visit aws.amazon.com/redshift.\\xa0 \\nPortugus\\n  Contact Sales\\nAbout Respond.io\\nFranais\\nHassan says, Our workflows require a sophisticated architecture, with thousands of executions running per minute. With AWS Lambda and AWS Fargate, we can manage this seamlessly, without worrying about security patching and server maintenance. \\nHassan Ahmed CTO and Cofounder, Respond.io \\n           2023 \\n 100+ Million \\nEspaol\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers. \\nFurthermore, users can conduct extensive searches within chat logs to understand their customers needs and challenges and obtain comprehensive reports that guide strategy. Business decision-makers can explore factors like average response times, problem resolution success rates, peak hours for sales inquiries, and other business-critical data.\\nAmazon ECS is a fully managed container orchestration service that makes it easy for you to deploy, manage, and scale containerized applications. \\nRespond.io is a software as a service (SaaS) platform that helps companies manage all its customer messaging in one place. For example, a retailer may receive customer support requests and sales inquiries through a variety of messaging channels. These messages are filtered into the Respond.io platform, where customer support and sales staff can address them in an organized and efficient manner.\\n Customizable automations\\n Amazon OpenSearch Service\\n\\nRespond.io also provides its customers with extensive reporting features that help them glean powerful insights from the vast amount of data created through customer messaging. Its reporting module is powered by Amazon OpenSearch Service. This means customers can obtain reports in milliseconds and analyze variables, like which messaging channels their customers prefer, peak messaging times, and additional insights that guide operations and marketing strategies.\\nAmazon OpenSearch Service makes it easy for you to perform interactive log analytics, real-time application monitoring, website search, and more. OpenSearch is an open source, distributed search and analytics suite derived from Elasticsearch. \\nBased in Kuala Lumpur, Malaysia, with offices in Hong Kong, Respond.io is a comprehensive customer conversation management software that facilitates seamless marketing, sales, and support communications across instant messaging, web chat, and email. \\n Get Started\\n\\nmessages stored in Amazon DynamoDB \\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\nOpportunity | Enhancing and Scaling a Powerful Business Messaging Platform  \\n \\n 2+ Billion\\n         \\nOutcome |\\xa0A Cutting-edge Product and a Rapidly Growing Business\\n AWS Services Used\\n Overview\\n ()\\nBahasa Indonesia\\n OpenSearch Reporting\\nSince adopting AWS, Respond.io is managing over 100 million messages per month for more than 10,000 customers, serving a range of multinational corporations. In September 2022, the company received $7 million in Series A venture funding, and executives see no limits to continued expansion. \\n  Contact Sales \\n\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\n\\nRespond.io was running its platform on a serverless architecture from a different cloud provider, but its founders quickly realized that the platform was not equipped to scale. In fact, users were experiencing chat log search latencies and system delays. To scale and continue to serve enterprises like Toyota, McDonalds, and Decathlon, the company needed a reliable, flexible, and robust cloud provider. \\n ()\\nto handle communication workflows \\nRespond.io currently stores over 1.5 TB from 2.6 billion messages in Amazon DynamoDB, a fully managed, serverless NoSQL database. The platform also uses Amazon Simple Storage Service (Amazon S3) with Amazon Athena to export these messages, facilitating efficient retrieval and minimal search latency. This gives users a way to quickly search and access customer chat logs, follow up on previous customer exchanges, and effectively manage marketing, sales, and support communications.\\n Low latency\\nsales and support messages exchanged monthly \\n Amazon Elastic Container Service (Amazon ECS)\\nHassan concludes, We couldnt have grown and survived without AWS, considering the complexity and the sheer volume of data we handle today. \\nRespond.io continues to develop an innovative SaaS product that stands out in the marketplace. The product delivers efficient communication across 15 different messaging channels, and its user-friendly dashboard and customizable, no-code workflows make it easy for companies to handle multiple inquiries. The platforms extensive reporting features and low-latency chat capabilities bring additional value, handing Respond.ios customers a competitive edge.\\nAmazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. \\nRespond.io is a Malaysia-based SaaS company whose business messaging platform helps organizations seamlessly manage customer communications. To enhance its platform and scale in response to growth, Respond.io migrated to AWS.\\nTrke\\ndelivering comprehensive marketing insights \\nEnglish\\nRespond.io transformed its business messaging platform with AWS Serverlessexpanding search capabilities to efficiently handle over 100 million messages per month. \\nSolution |\\xa0Supporting a Massive Expansion in Product Features and Customer Volume\\nDeutsch\\n Respond.io Scales Its Messaging Platform and Connects 10,000+ Companies with Customers on AWS\\nWe live in an era in which consumer-facing companies cannot survive, much less thrive, without a strategic approach to communicating with customers via WhatsApp, Instagram, and other messaging applications. Companies capable of handling marketing and 1:1 conversation across major messaging channels have a strong edge over those with limited options.\\nTing Vit\\nItaliano\\n\\nRespond.ios founders had experience with Amazon Web Services (AWS) and decided to migrate to AWS. Hassan Ahmed, CTO and cofounder of Respond.io, says, Were expanding our platforms features and our user base is growing rapidly. Considering the extensive infrastructure that AWS offered, we were confident in AWS ability to help us scale.\\nWe couldnt have grown and survived without AWS, considering the complexity and the sheer volume of data we handle today. \\n Amazon DynamoDB\\nfor efficient analysis of customer chat logs  \\nLearn more\\xa0\\nCustomer Stories /\\xa0Software and Internet \\nToday, Respond.io has migrated 90 percent of its workloads to run on a serverless architecture on AWS Lambda. As a result, the companies it serves can now customize and automate workflows. Administrators can create a simple, no-code workflow that triggers an automatic response to incoming messages containing specific keywords, and they can create rules for assigning support tickets based on staff availability, time-in-queue, and many other factors.\\n AWS Lambda\\nRespond.io leverages Amazon Elastic Container Service (Amazon ECS), AWS Fargate, AWS OpenSearch Service, and Amazon DynamoDB to build a low-latency, scalable platform with robust search and reporting capabilities. Since adopting AWS, Respond.io is managing over 100 million messages per month for more than 10,000 customers, serving a range of multinational corporations. \\nPortugus\\nFranais\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers.  Learn more\\xa0\\n 30\\niptiQ uses a common code base for its European partners and has developed a single API to allow any of them to connect to its technology, regardless of the specific product and market combination. To accommodate individual requirements, iptiQ tailors what each partner gets and adapts its offering to the different categories of insurance that their partners customers need. Using AWS, this flexibility is possible.\\nEspaol\\n                \\nThe scale-up relies on a number of services, including Amazon Relational Database Service (Amazon RDS), Amazon Elastic Kubernetes Service (Amazon EKS), Amazon SageMaker and AWS Lambda, which helped it set up, operate, and scale its relational database in the cloud with just a few clicks. Pozzoli also values the ability to easily draw on developer resources. There\\'s a large engineering pool with extensive experience on AWS, which allows you to ramp-up your teams quickly, he says.\\n\\n 1%\\nIn addition, iptiQ has reduced partner onboarding timefrom around 68 months, which is common with other insurers, to a few weeks.\\n 2022\\n                  AWS Customer Success Story: iptiQ by Swiss Re | Amazon Web Services \\n\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\nLearn how \\xa0\\n \\nIn Europe, iptiQ launched its Property & Casualty insurance business entirely using Amazon Web Services (AWS), knowing that it needed to grow and develop its products at speed. Using AWS has been pivotal to our success, says Claudio Pozzoli, chief technology officer (CTO) at iptiQ EMEA. Our business is simplifying complex insurance practices, not IT maintenance. With our platform built on AWS, we can better support our partners, give them the products they need faster, and make the digital journey easier for their customers.\\n Amazon Lambda\\n             Maecenas efficitur neque ac ex porta \\n                  Organizations of all sizes use AWS to increase agility, lower costs, and accelerate innovation in the cloud. \\nBuild, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.  Learn more\\xa0\\niptiQ, a B2B2C insurer and division of Swiss Re, provides a white-label, digital insurance solutions built on AWS that helps its consumer-brand partners sell insurance policies that are complementary to their core businesses.\\xa0 \\nThese days, its not unusual to find yourself buying a mobile phone subscription from a grocery store, signing up for a credit card from your favorite sports team, or even getting home insurance when you buy furniture. Out-of-category purchasing, as its called, is becoming more common, especially for financial services.\\n AWS Services Used\\nAmazon Relational Database Service (Amazon RDS) is a collection of managed services that makes it simple to set up, operate, and scale databases in the cloud.  Learn more\\xa0\\n             ipsum et velit consectetur \\n ()\\nBahasa Indonesia\\n Donec placerat \\n  Contact Sales \\n\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\n\\n ()\\nData protection is critical in a highly regulated sector such as insurance. Using AWS, we can easily comply with the security standards in our industry, says Pozzoli. We have peace of mind that our brand and reputationand those of our partnersare fully protected.\\u202f\\nLearn more\\xa0\\n            \\n Get Started\\n About iptiQ\\nSwiss Res iptiQ Helps its Partners Deliver Simple, Digital Insurance Solutions on AWS\\n 2\\n AWS Customer Success Stories\\nTrke\\nEnglish\\n Amazon RDS\\nWith our platform built on AWS, we can better support our partners, give them the products they need faster, and make the digital journey easier for their customers. \\n Sed quis \\nCustomer Stories / Insurance \\nUsing AWS, iptiQ has the availability, speed, and flexibility to keep innovating. Its solution makes life easier for consumers, both when buying insurance and making claims. In addition, it has reduced partner onboarding timefrom around 68 months, which is common with other insurersto just a few weeks. \\nAmazon EKS is a managed Kubernetes service to run Kubernetes in the AWS cloud and on-premises data centers. \\nThis innovative model is known as business-to-business-to-consumer (B2B2C) insurance, and the market for such services is set to almost triple in size between 2020 and 2031. iptiQ makes it easier for brands to sell insurance that complement their core productswhile giving those companies customers a better insurance-buying experience.\\n             Nulla nisl massa, ullamcorper id \\nDeutsch\\nTing Vit\\nPellentesque quis dui vel nunc cursus. elementum ac eget null integer interdum \\n             sodales felis pellentesque et \\n Swiss Res iptiQ Helps its Partners Deliver Simple, Digital Insurance Solutions on AWS\\nItaliano\\n\\n Amazon EKS\\nFor iptiQ, delivering a great experience is as important as ensuring that security is covered. So, if you find that your life is being made a little bit easier by the convenience of buying insurance services from your preferred brand, it might well be iptiQ thats powering it. And as the company continues its rapid growthGross Written Premium grew 95 percent in 2021in Europe its using AWS to gain the speed and availability it needs to deliver innovative insurance purchasing options to brands and consumers.  \\niptiQ, a scale-up division of reinsurer Swiss Re, is making it easy for consumer brands to sell insurance to their customers. As a white-label insurance provider, iptiQ forms partnerships with insurance intermediaries and leading companies such as home furnishings retailer IKEA and real-estate marketplace ImmoScout24. Today, more than 50 partners embed or integrate our insurance solutions into their products or customer journeys, says Andreas Schertzinger, chief executive officer (CEO) at iptiQ EMEA. This means that more than 1.6 million consumers benefit from our affordable and convenient products.\\nClaudio Pozzoli Chief Technology Officer, iptiQ EMEA \\nPortugus\\n Amazon SageMaker\\nAWS Lambda\\nFranais\\n           2023 \\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers. You can trigger Lambda from over 200 AWS services and software as a service (SaaS) applications, and only pay for what you use.  Learn more\\xa0\\nEspaol\\nADP pursued a novel approach to unify its global UX and improve latency, cost, and performance. The serverless model looked like a good way to handle higher traffic and be active across multiple regions, says Anderson Buzo, chief architect at ADP. And with serverless architecture, the cost is based on what we actually use, not what we deploy. The company began migrating its flagship application to Amazon Web Services (AWS) in 2019 to take advantage of the benefits that come from a robust computing network. Now the application runs entirely on AWS, and clients are enjoying improved quality, lower latency, and a seamless UX. The migration to a serverless model on AWS has also accelerated the pace of innovation because ADP teams no longer have to spend time on infrastructure management. \\nfor bursts of traffic to eliminate throttling and errors\\nAWS AppSync creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data.\\xa0\\nAWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers.\\n\\n Scaled\\nThe application usersthe employees of ADP client companiesare benefiting from ADP innovations, which include intelligent self-service and chatbot functionality in some regions. The increased flexibility that ADP now offers means that the application maintains a 4.5 rating from users on mobile application marketplaces. With a new, unified user experience, time to market has been reduced, and the company can onboard new clients more quickly. ADP has also accelerated feature delivery substantially. Its teams are happy to be able to focus on what they do best. Using AWS solutions, the talent on our team is doing actual product engineering work instead of worrying about infrastructure, says Ramachandran. \\n\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\n About ADP\\n \\nAfter migrating to AWS, ADP adopted AWS AppSync to bolster the reliability of the application and offer a better experience with offline-first design. By designing an offline-first architecture, the team is developing a solution that pushes ADP Mobile and MyADP data to user devices as new data becomes available. This approach makes the application more resilient to faults and gives users access to recently updated data even if their network connection is slow.\\xa0\\n AWS Fargate\\n 4.5+\\n         \\n AWS AppSync\\n AWS Services Used\\nLearn how ADP in human resources evolved a global UX using AWS serverless technologies. \\n Amazon ECS\\nAutomatic Data Processing (ADP) wanted to modernize its flagship desktop and mobile solutions, MyADP and ADP Mobile, so that its over 17 million users had a seamless user experience (UX). The company, a global technology company providing human capital management (HCM) and enterprise payroll services, strives to build innovative products. Low latency and a high-quality UX are a must for the enterprise.\\xa0\\n ()\\nBahasa Indonesia\\nAutomatic Data Processing (ADP) provides payroll, human resources, and tax services to businesses around the world. The company processes the payroll of one in six American employees.\\n  Contact Sales \\n\\nCustomer Stories / Software & Internet \\n\\n ()\\n Resiliency\\nLearn more\\xa0 \\nLearn more\\xa0\\n Portability\\n Overview\\nADP used AWS tools to resolve challenges within its application. The company required a solution that could scale seamlessly to accommodate the rush of workers that clock in during a 90-second window around the beginning of each hour. However, ADPs prior system took 60 seconds to scale as traffic doubled. Engineers worked quickly to develop a proof of concept using AWS Fargate, a serverless, pay-as-you-go compute solution that scaled rapidly. ADP uses AWS Fargate in tandem with Amazon Elastic Container Service (Amazon ECS), a fully managed container orchestration service for containerized applications. Were using AWS because we want to be a product development team and not an infrastructure management team, says Ramachandran.\\xa0As part of the application modernization, ADP started to build a new generation of microservices in AWS Lambda, a serverless, event-driven compute service. ADP further increased resiliency by deploying in multiple availability zones. After the migration, the team began optimizing costs. Today, we are using AWS solutions like a Ferrari, but were paying the price of a regular car because of our serverless architecture, says Ramachandran. In addition to saving money, ADP has increased staff productivity. Before using AWS, product developers had to coordinate and align with multiple internal teams to troubleshoot issues with databases and other resources. After migrating to managed services on AWS, development teams own their resources fully, and the company now spends much less time on support and maintenance.\\xa0\\n Get Started\\nSolution |\\xa0Unlocking Resilience Through Off-line Architecture and AWS Services\\napp store rating maintained \\nTrke\\nEnglish\\nADP processes payments for one in six American workers, and the company is expanding globally. To meet quality and latency goals, the company is committed to consolidating, standardizing, and modernizing its application, which is used by over 17 million people and more than 470,000 companies. Although ADP Mobile and MyADP are used as the delivery mechanism for all ADP services, the company wanted to present a more consistent brand to customers with a unified global experience for common pillars like payroll, benefits, retirement, and taxes.\\xa0\\nDevi Ramachandran Senior Director, DevOps, ADP \\nwith latency-based routing\\nAmazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service that simplifies your deployment, management, and scaling of containerized applications.  Learn more\\xa0\\n Evolving ADPs Single Global Experience in MyADP and ADP Mobile Using AWS Lambda\\nDeutsch\\nOutcome | Moving Toward Global Deployments on AWS\\nTing Vit\\nWere using AWS because we want to be a product development team and not an infrastructure management team.\\nItaliano\\n\\nAfter three years, all of the applications critical systems have been migrated to the cloud. We are a total AWS shop right now, says Ramachandran. Serverless architecture has opened new possibilities for innovation. The team is now focused on global deployments so that improvements developed in one region will automatically deploy globally. When we build a feature in the United States or Europe, we can simply bring it to the app, and everybody can have it, says Buzo. On AWS, we can build a global app.\\xa0 \\nADP had to innovate to create a single experience for disparate systems of record without introducing error. The speed at which pay statements open up should be the same speed at which benefits enrollment open, but these are two different sources of content on two different sets of infrastructure, says Devi Ramachandran, senior director of DevOps at ADP. Thats been our challenge from the beginning, and migrating our systems to AWS made everything simpler. ADP also had to simplify the ADP Mobile and MyADP application programming interface (API) access that is provided by those different infrastructures. To streamline data aggregation on the backend, the company used AWS AppSync, which creates serverless GraphQL and Pub/Sub APIs that simplify application development. Using AWS AppSync, ADP can bring together data from the various backends and sources into a single endpoint.\\nfor global UX achieved \\n Reduced Latency\\nOpportunity |\\xa0Using AWS to Create a Global User Experience for 17 Million People\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nPortugus\\nImproved through multi region architecture\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers.  Learn more\\xa0\\nEspaol\\n*.MsoChpDefault {\\n\\n 2022\\nThe NAEM solution built on AWS helps reduce the average processing time of adverse events from over 90 minutes to under 15 minutes, achieving over 80 percent time savings. Clients use an electronic data interchange built on AWS to send adverse-event report files to a system that initiates the NAEM workflows. These reports get stored securely using Amazon Simple Storage Service (Amazon S3), an object storage service offering industry-leading scalability, data availability, security, and performance. Automation services pick up files from Amazon S3 and route them to an AI-augmented application that supports clinical experts, who complete and review cases. Then, they deliver the files back to the client as industry-standard E2B (R2) or E2B (R3) files.\\n\\n \\nmso-hansi-font-family:Calibri {\\nmso-fareast-theme-font:minor-latin {\\n AWS Services Used\\nIndegenes NAEM uses AI to help agents automate the reporting of adverse events, product-quality complaints, and allied medical information. Its intelligent call flow assists with automatic capture and population of adverse event data, which makes the process faster and more accurate. Using AWS, our users can make judgment decisions readily, perform duplicate checks, and accurately triage and validate cases, says Vladimir Penkrat, Indegenes Practice Head of Safety and Regulatory Affairs.\\n*, sans-serif {\\nFounded in India in 1998, Indegene is a technology-led healthcare solutions provider. Now in 15 offices worldwide, the company helps its clients with digital transformation, from research and development to management to commercial applications. \\nBahasa Indonesia\\nLearn how Indegene helps life sciences companies streamline and scale adverse event reporting while generating efficiencies and cost savings, using its solution built on AWS.\\nIn 2021, a global pharmaceutical company asked Indegene for help addressing a sudden increase in case volume after a product launch. The solution needed to work with its enterprise environment to properly exchange files and leave full audit trails. The company implemented an upgraded version of NAEM, which uses Amazon Comprehend, a natural-language processing service that uses machine learning (ML) to uncover valuable insights and connections in text. NAEM also uses a related service, Amazon Comprehend Medicalwhich uses ML that has been pre-trained to understand and extract health data from medical textto extract information from doctors notes and clinical trial reports. The solution has scaled to process about half a million cases, automates over 400 rules, and uses AI to improve overall processing efficiency by 60 percent. \\nmso-fareast-font-family:Arial {\\n Overview\\n Cost optimization\\n\\tpage: WordSection1;\\nmso-hansi-theme-font:minor-latin {\\n* {\\n\\np.MsoNormal, li.MsoNormal, div.MsoNormal {\\nLearn more\\xa0\\nmso-font-pitch:variable {\\n AWS Lambda\\nFranais\\nSolution | Extracting Insights from Adverse-Events Data Using AWS Services \\xa0\\n ()\\n  Contact Sales \\n 60%\\nTarun Mathur Chief Technology Officer, Indegene \\nTrke\\nIndegene began using AWS in the early 2000s, when it adopted Amazon Elastic Compute Cloud (Amazon EC2) to provide secure and resizable compute capacity for its workloads. This relationship has strengthened, and today, Indegene is an AWS Partner. Our mission is to help pharmaceutical organizations be future ready and drive business transformation by using technology in an agile, efficient way, says Mathur. Keeping up with all the new AWS services and capabilities has been a good challenge, and the variety of training programs and great technical support is a bonus. AWS is leading the pack in innovation. \\nEnglish\\nmso-ascii-font-family:Calibri {\\nTing Vit\\nPortugus\\nreduction in cases requiring follow-up \\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nOn AWS, we are more efficiently capturing data about medicines and maintaining full compliance with global regulations, which results in a much healthier patient population, says Sameer Lal, Indegenes senior vice president. And thats what we are hoping for in the end: delivery to a much healthier world. \\nIndegene also uses AWS Lambda, a serverless, event-driven compute service, to direct files into its database, which is built using Amazon Relational Database Service (Amazon RDS), a collection of managed services that make it simple to set up, operate, and scale databases in the cloud. For security, the company uses AWS services to implement predefined actions, such as how long the system retains certain pieces of information. Indegene uses encryption certificates for data in transit and at rest, and clients can access a virtual private cloud through the AWS Client VPN.\\nmso-bidi-theme-font:minor-bidi {\\n}\\n\\nUsing AWS Auto Scaling, which monitors applications and automatically adjusts capacity, Indegene can scale on demand to serve clients of virtually all sizes without having to provision physical infrastructure and servers. AWS is our go-to cloud infrastructure, Mathur says. We have had virtually no downtime. Even with spikes or surges in volumes, our systems are fully available. The cost savings, innovation, security, compliance, and reliability are unparalleled.\\nTimes New Roman {\\n About Company\\nAmazon Comprehend Medical is a HIPAA-eligible natural language processing (NLP) service that uses machine learning that has been pre-trained to understand and extract health data from medical text, such as prescriptions, procedures, or diagnoses.  Learn more\\xa0\\nMost pharmaceutical companies process over 50 percent of PV cases manually to record adverse events, enter them into a specialized safety database, reconcile with corresponding medications, and submit data to health authorities using industry-standard E2B protocols. About 75 percent of cases require follow-up days or weeks later. Ultimately, data elements are compiled into a loose-text format, known as a narrative, which articulates the cases disposition. This process is inefficient and diminishes the potential value of analytics. \\nUsing its automated workflows, Indegene can extract structured and unstructured data and send it to the clients enterprise environment for submission and downstream analytics. Pharmaceutical companies can produce safer medicines with fewer side effects, supporting a healthier population. AWS is already well respected in the life sciences industry, says Tarun Mathur, Chief Technology Officer at Indegene. Many of the big pharmaceutical companies use AWS, so many issues related to IT approvals and certifications are accelerated when youre deploying your solution to the AWS environment.\\nAmazon Relational Database Service (Amazon RDS) is a collection of managed services that makes it simple to set up, operate, and scale databases in the cloud.  Learn more\\xa0\\nimprovement in adverse event management efficiency  \\nDeutsch\\nmso-pagination:widow-orphan {\\n Amazon S3\\nItaliano\\n Efficient scaling\\nmso-fareast-font-family:Calibri {\\n Amazon Comprehend Medical\\n 80%\\nAWS is our go-to cloud infrastructure. We have had virtually no downtime. Even with spikes or surges in volumes, our systems have been fully available. The cost savings, innovation, security, compliance, and reliability are unparalleled. \\nmso-generic-font-family:roman {\\nIndegene is growing its AI and ML capabilitiesexpanding the intake channels and formats the system can ingestto include much greater unstructured capability. The company plans to incorporate more automation into the user interface with smarter intake functionality. The next generation of NAEM will be even more scalable by using Amazon ElastiCache for Redisan in-memory data store that provides sub-millisecond latency to power internet-scale near-real-time applications. This upgrade will substantially reduce turnaround time while maintaining quality. \\n\\nThe solution has also reduced the number of follow-ups by 50 percent. Our clients can look at a patients case and make the right judgment based on the patients risk, says Penkrat. They can effectively make use of high-throughput activity that is compliant and that sometimes needs to be processed in 1 day. Our clients use the dashboards and the intelligence that the system provides to properly prioritize case types. \\n ()\\nmso-ascii-theme-font:minor-latin {\\ndiv.WordSection1 {\\nfor database management  \\n 50%\\n Indegene Reduces Adverse-Event Reporting Time for Its Clients by 80% Using AWS\\nArial, sans-serif {\\nThe pharmacovigilance (PV) process for life sciences companies still relies heavily on inefficient and manual operations. Indegene, a technology-led healthcare solutions provider, sought to transform this process to help its clients drive efficient, meaningful PV outcomes. Using Amazon Web Services (AWS), Indegene built a modern, agile, efficient, and compliant solution for pharmaceutical safety case processing: the NEXT Adverse Event Management System (NAEM). NAEM helps pharmaceutical companies reduce turnaround time for case reporting while improving quality, traceability, reconciliation, and cost efficiency. Using NAEM, organizations have boosted efficiencies by 60 percent using artificial intelligence (AI) and advanced analytics, delivering effective outcomes for patients in over 50 countries. \\n Amazon RDS\\nto handle about half a million cases  \\nreduction in time to report adverse events  \\nAmazon Simple Storage Service (Amazon S3) is an object storage service offering industry-leading scalability, data availability, security, and performance. \\nOutcomes | Contributing to a Healthier Patient Population Using Solutions Built on AWS\\xa0\\n Get Started\\nCustomer Stories / Life Sciences \\nOpportunity | Improving Adverse Event Management Process Efficiency\\nAWS Lambda\\nFranais\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers.  Learn more\\xa0\\n           2023 \\nEspaol\\n  Pause slide rotation   \\nNext\\nAmazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.   Learn more\\xa0\\n\\nThanks to this optimization, the company has been able to dedicate 30 percent more resources to innovation and speed up coding and testing times, while scaling platform performance tenfold. In addition, Dexatek is now looking to new markets and has launched a product on the AWS Marketplace.\\nThe ability to easily expand the IoT platform is helping Dexatek focus on new markets. Chen, for one, is already looking to a near future where the company goes beyond smart homes. We have the expertise and the capabilities to support the transfer of IoT data from devices and sensors on cars just as well as in the home, which means fleet management could be an area of interest for the future, he says.\\nAmazon Elastic Compute Cloud (Amazon EC2) offers the broadest and deepest compute platform, with over 500 instances and choice of the latest processor, storage, networking, operating system, and purchase model to help you best match the needs of your workload.   Learn more\\xa0\\nPrev\\n\\nDexatek Technology, headquartered in New Taipei City, designs, manufactures, and promotes Internet of Things (IoT) consumer electronic products. Founded in 2003, the company provides solutions for a range of smart appliances, covering home security, wellbeing, and more. \\xa0\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\nWith AWS, Dexatek can continue pursuing expansion, using the platforms scalability to seize new business opportunities. As a first step, the company has launched its Dexatek IoT Core solution on the AWS Marketplace to offer businesses an out-of-the-box solution, complete with mobile apps, that provides their products with smart capabilities.\\n \\nPlay\\nIn addition to being simpler to administer, the platform scales automatically as more IoT connections are added, and data travels between the platform and devices 10 times faster. With AWS IoT Core, we can drive growth without worrying about platform workloads and offer businesses a level of performance that exceeds many of our competitors, comments Chen.\\n AWS IoT Core lets you connect billions of IoT devices and route trillions of messages to AWS services without managing infrastructure.  \\n Get Started\\nJerry Chen Chief Executive Officer, Dexatek Technology \\n         \\nBy optimizing its platform with AWS IoT Core and going serverless, Dexatek has tightened the security of device connections through mutual authentication and end-to-end encryption. I think the overall stability of the platform is also greater, adds Chen, which means I can go to bed at night and not think about problems such as a server causing the platform to go down.\\n AWS Services Used\\nDexatek hoped to create a more scalable IoT platform that reduced management time while maintaining a high level of security. Jerry Chen, chief executive officer at Dexatek Technology, explains, We had to scale our instances manually and schedule regular maintenance to update servers as well as the security certification for our MQTT connections. We wanted to eliminate these administrative activities so we could focus on development and growing the company.\\nincrease in processing performance\\n ()\\nBahasa Indonesia\\n 10x\\nWorking closely with AWS, Dexatek successfully migrated to AWS Lambda with AWS IoT Core to securely connect smart devices, and Amazon DynamoDB to easily store and query device data. The strong working relationship with AWS helped the Dexatek team save a lot of work. We completed development, including all APIs and basic testing, in under three months instead of six to eight months as expected for a project like this.\\nAutomated encryption and authentication\\n\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\n\\n ()\\nCustomer Stories / Hi Tech, Electronics & Semiconductor \\n  \\n Greater security\\n AWS IoT Core\\nTo drive growth in this expanding market, Dexatek wanted to optimize its Amazon Web Services (AWS) infrastructure that supported the processing of smart-device data. The infrastructure was based on a combination of Amazon Elastic Compute Cloud (Amazon EC2) instances and Amazon Simple Storage Service (Amazon S3) to handle the transfer of information to and from devices via the MQTT protocol.\\n Overview\\nWe estimate that by moving to AWS IoT Core along with AWS Lambda, we can shift 30 percent more IT resources to product development.\\nDexatek increased the performance of its Internet of Things (IoT) platform, enhanced security, and lowered management time by migrating to AWS IoT Core.\\nOpportunity | Making Smart Devices Easier to Scale and Less Management Intensive\\n Dexatek Optimizes Its IoT Platform and Boosts Spend on Innovation by 30% with AWS\\n Amazon EC2\\nTrke\\n  Resume slide rotation  \\nEnglish\\nOutcome | Creating Opportunities for New Markets with AWS\\nLowered coding and testing times from months\\nThe company is currently experimenting with Amazon SageMaker to help train machine learning models and AWS IoT Greengrass to leverage pre-built software components that would speed up delivery of the IoT device software. If your goals are to reduce costs and make IoT devices smarter, then AWS has what you need, Chen concludes.\\n About Dexatek Technology\\n 30% \\nDexatek can also onboard businesses quicker, launching IoT platform demos for new customers in less than a weeka process that could previously take three months. This is because AWS IoT Core makes coding easier and testing periods shorter. Chen explains, We give the engineers a heads up on what we need them to do, and after three to five days, theyre saying, Its done.\\nSolution | Freeing Up Resources for Innovation with AWS IoT Core \\xa0\\n < 5 days\\nDexatek Technology, based in Taiwan, gives electronic consumer products smart capabilities using its IoT solutions. To optimize its IoT platform for processing data from smart devices, Dexatek migrated to AWS IoT Core and AWS Lambda along with the Amazon DynamoDB database service.\\nDeutsch\\n Amazon DynamoDB\\nTing Vit\\nItaliano\\n\\nmore available resources for innovation\\n  Contact Sales \\nLearn more\\xa0\\nWith development finished, Dexatek Technology is completing a final technical review before fully adopting the AWS IoT Corebased serverless architecture. Chen expects it to significantly reduce the amount of infrastructure management that IT personnel will need to perform. We estimate that by moving to AWS IoT Core along with AWS Lambda, we can shift 30 percent more IT resources to product development, he says.\\nDexatek Technology helps consumer electronics companies incorporate smart technology into products like light switches, thermostats, and air-conditioning units. It equips businesses with Internet of Things (IoT) capabilities so that customers can remotely monitor and control their devices, such as adjusting the temperatures of their homes or scheduling when their lights come on. The company is taking advantage of the growing market for smart home products, which is expected to attract $173 billion in consumer spending worldwide by 2025.\\nWith optimization as its goal, Dexatek looked at moving from Amazon EC2 to AWS Lambda serverless service. In addition, it began investigating AWS IoT Core to join, manage, and scale its smart device connections without having to think about security. Says Chen, We decided to engage with AWS Solutions Architects to make sure we proceeded correctly. We wanted them to double-check everything we did to avoid any delays in the optimization process.\\nPortugus\\nAWS Lambda\\nFranais\\nAchieved HIPAA compliance quickly\\nFounded in 2016, LifeOmic has over 100 employees and a variety of healthcare software solutions. The company started by creating Precision Health Cloud, a secure cloud solution that integrates and indexes disparate data sources, including genomic, clinical, imaging, and population data. This system currently stores 400 million clinical data points and 500 billion genetic variants, including 55 billion unique genetic variants. In addition to supporting healthcare organizations, LifeOmic wanted to offer solutions to help consumers live healthier lives. After it had achieved a solution that was compliant with HIPAA and the HITRUST Alliance, LifeOmic developed mobile apps designed to empower individuals to manage their own health. We can support all of these products on the same solution and reuse a lot of code, so were able to achieve a lot and expand into new marketplaces with a relatively small team, says Anthony Roach, technical director at LifeOmic.\\nEspaol\\nScales to meet peak demand\\n\\n AWS Services Used\\n  Contact Sales \\n AWS Step Functions\\n\\nMakes an average of 100 production deployment updates per day\\nChris Hemp Vice President of Engineering, LifeOmic\\xa0\\nSupports a growing base of over four million users\\n \\nWith its secure, scalable serverless architecture on AWS, LifeOmic is equipped to support the full continuum of healthcare, from research and preventive medicine to diagnosis and treatment management. We wouldnt have had nearly as much breadth if we hadnt used AWS, says Roach. Four million users and counting have downloaded LifeOmics mobile applications, which connect with wearable devices and pacemakers. The company can scale to meet demandsuch as when New Years resolutions led to a three-times increase in application sessions in January compared to Decemberusing simple controls without needing to add new hardware.\\nAmazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \"front door\" for applications to access data, business logic, or functionality from your backend services. \\n Achieving Scalable, HIPAA-Compliant Data Storage on AWS\\n Get Started\\n About LifeOmic\\nBy using fully managed serverless solutions on AWS, LifeOmic was able to reduce or remove its ongoing maintenance and operations costs, launch quickly, and prepare to scale with agility as the company adds new products and features. The ease and speed of serverless development on AWS has helped our small team deliver a large set of features in just a few months, says Chris Hemp, vice president of engineering at LifeOmic. \\n LifeOmic Achieves up to 50% Cost Savings after Building Serverless Architecture on AWS\\nLifeOmic has built a secure health solution that powers analytics, interventions, and engagement solutions for improving health outcomes across the continuum of care, from prevention and wellness to clinical care and research. \\n ()\\nBahasa Indonesia\\nBecoming multitenant to support everything from small clinical practices to large hospital systems was also an important goal for LifeOmic. To achieve this, the company needed scalable data stores, and it saw that AWS provided a variety of potential solutions. By using managed services like Lambda, LifeOmic could keep operational costs low and empower its team to focus on developing software, not running the backend. Some companies try to do cloud-agnostic development, but they lose the benefits that a designated cloud vendor can provide, says Roach. On AWS, we gain everything we need, from serverless code to data stores, so we dont have to worry about multiple vendors and compatibilities. \\nIn April 2020, LifeOmic sought to become compliant with the Federal Risk and Authorization Management Program, and it achieved this goal by April 2021. We wouldnt have achieved these federal standards in 1 year if we werent using AWS, says Hemp. Using AWS, we were able to keep up with the requirements for documentation and security and have the support that we needed. \\nAvoids infrastructure costs and capital expenses\\n\\nAchieved Federal Risk and Authorization Management Program compliance in 1 year\\n\\nInitially, LifeOmic focused on building genomic pipelines using AWS services such as Amazon Elastic Container Service (Amazon ECS), a fully managed container orchestration service. Early on, the company started building APIs and began using AWS Lambda to speed up API development processes as soon as the service became HIPAA eligible. By using AWS Lambda with a Hypertext Transfer Protocol interface layered on, LifeOmics developers were able to write and deliver code with ease, even if they were unfamiliar with AWS Lambda.\\n ()\\nSoftware company LifeOmic knew that to improve health outcomes, researchers, clinicians, and device manufacturers in healthcare and biotech organizations needed a secure solution for interaction and data management. To build this solution quickly and cost efficiently, LifeOmic chose a serverless architecture on Amazon Web Services (AWS).\\xa0\\n Amazon Elastic Container Service (Amazon ECS)\\nLearn more\\xa0\\n\\xa0\\n Benefits of AWS\\nAmazon ECS is a fully managed container orchestration service that helps you easily deploy, manage, and scale containerized applications. It deeply integrates with the rest of the AWS platform to provide a secure and easy-to-use solution for running container workloads in the cloud and now on your infrastructure with Amazon ECS Anywhere. \\nGrowing the company from the ground up on AWS has helped LifeOmic focus on innovation instead of infrastructure management. Next, the company is looking into using Amazon Timestream, a serverless time series database service, to add new features that call for continuous data, such as intraday heart rate and continuous glucose monitoring. LifeOmic also continues to expand its customer base and is seeing growing trust in the cloud. Our customers are confident in the reliability of AWS, says Roach. That and our ability to put out new features so quickly have created a winning combination. \\nTrke\\nThe company has also realized business benefits, including faster time to market from using automation to make an average of 100 production deployment updates in 1 day. LifeOmic has also achieved cost savings of 3050 percent by adopting Lambda, including using provisioned concurrency and Compute Savings Plans, a flexible pricing model that offers low prices on AWS Lambda usage. The company has also seen success recruiting and retaining employees, who are excited to use AWS services. Many participate in AWS Training and have either renewed their AWS Certifications or have achieved one for the first time.\\nEnglish\\nReduced costs by 30%50%\\n Scaling Healthcare Applications Using AWS Lambda\\n Amazon API Gateway\\nImproved employee recruitment and retention \\nDeutsch\\nWhen Amazon OpenSearch Servicewhich makes it easy to perform interactive log analytics, near-real-time application monitoring, and website searchesbecame HIPAA eligible, LifeOmic was able to add analytics and search features to its Precision Health Cloud. LifeOmic now uses OpenSearch Service as its biggest data store, housing 500 billion documents. Another milestone for LifeOmic was joining AWS Activate, a program that offers startups free tools, resources, and more to quickly get started on AWS. The program offered insights into the AWS road map, helping LifeOmic make its own decisions about its next steps.\\nAWS Step Functions is a low-code, visual workflow service that developers use to build distributed applications, automate IT and business processes, and build data and machine learning pipelines using AWS services. \\nTing Vit\\nThe ease and speed of serverless development using AWS has helped our small team deliver a large set of features in just a few months.\\xa0 \\n Continuing to Grow and Innovate\\nItaliano\\n\\nIn LifeOmics pipeline, applications make code initiation requests through Amazon API Gateway, a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. The pipeline then uses AWS Lambda to run code to retrieve data from Amazon DynamoDB, a fast, flexible NoSQL database service. And to achieve smooth workflows, LifeOmic uses AWS Step Functions, a low-code, visual workflow service that developers can use to build distributed applications and automate IT and business processes. Using AWS Step Functions, we can achieve long-running processes easily because everything is managed for us, says Roach.\\n2022\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers. You can trigger Lambda from over 200 AWS services and software as a service (SaaS) applications, and only pay for what you use.\\nLifeOmic decided to build its solution from the ground up on AWS because AWS services like AWS Lambdaa serverless, event-driven compute servicemake it simpler to process, store, and transmit protected health information, facilitating HIPAA compliance. It can take years for startups to meet HIPAA compliance requirements, says Roach. LifeOmic started under the assumption of meeting these requirements and more. We tackled and achieved the rigorous HITRUST CSF Certification in less than 6 months with zero corrective actions, and using AWS made it much easier.\\nPortugus\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successful_titles = ['\\n'.join(results['documents'][0])]\n",
    "successful_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe140969-e3e3-4bee-a434-26b9797cc779",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m PROMPT_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are an expert in all things hackernews. Your goal is to help me write the most click worthy hackernews title that will get the most upvotes. You will be given a USER_PROMPT, and a series of SUCCESSFUL_TITLES. You will respond with 5 suggestions for better hackernews titles.\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m[/INST]\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     15\u001b[0m mistral_response \u001b[38;5;241m=\u001b[39m replicate\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma16z-infra/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     },\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m suggestions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmistral_response\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(suggestions)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m PROMPT_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are an expert in all things hackernews. Your goal is to help me write the most click worthy hackernews title that will get the most upvotes. You will be given a USER_PROMPT, and a series of SUCCESSFUL_TITLES. You will respond with 5 suggestions for better hackernews titles.\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m[/INST]\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     15\u001b[0m mistral_response \u001b[38;5;241m=\u001b[39m replicate\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma16z-infra/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     },\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m suggestions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m mistral_response])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(suggestions)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/replicate/prediction.py:248\u001b[0m, in \u001b[0;36mPrediction.output_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    250\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    251\u001b[0m new_output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;28mlen\u001b[39m(previous_output) :]\n",
      "\u001b[0;31mModelError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = f'''[INST]\n",
    "You are an expert in all things hackernews. Your goal is to help me write the most click worthy hackernews title that will get the most upvotes. You will be given a USER_PROMPT, and a series of SUCCESSFUL_TITLES. You will respond with 5 suggestions for better hackernews titles.\n",
    "\n",
    "All of your suggestions should be structured in the same format and tone as the previously successful SUCCESSFUL_TITLES. Make sure you do not include specific versions from the SUCCESSFUL_TITLES in your suggestions.\n",
    "\n",
    "USER_PROMPT: {query_string}\n",
    "\n",
    "SUCCESSFUL_TITLES: {successful_titles}\n",
    "\n",
    "SUGGESTIONS:\n",
    "\n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "mistral_response = replicate.run(\n",
    "    \"a16z-infra/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70\",\n",
    "    input={\n",
    "        \"prompt\": PROMPT_TEMPLATE,\n",
    "        \"temperature\": 0.75,\n",
    "        'max_new_tokens': 2048,\n",
    "    },\n",
    ")\n",
    "\n",
    "suggestions = ''.join([str(s) for s in mistral_response])\n",
    "\n",
    "print(suggestions)\n",
    "\n",
    "print('====')\n",
    "\n",
    "print('PROMPT_TEMPLATE', PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9f50f-6d42-401a-a800-f3dd5fd6323b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chroma",
   "language": "python",
   "name": "chroma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
